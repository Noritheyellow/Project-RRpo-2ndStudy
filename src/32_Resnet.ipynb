{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import pickle\n",
    "import random\n",
    "import warnings\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# warnings.filterwarnings(action='ignore')\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "DATA_PATH = '/root/Workspace/DataWarehouse/stMary_RRpo'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6508 1800\n",
      "(6508, 1800) (6508,)\n"
     ]
    }
   ],
   "source": [
    "with gzip.open(f'{DATA_PATH}/21_230518_resamp_sliced125_filt_patient_stmary.pickle.gzip', 'rb') as f:\n",
    "    dataset = pickle.load(f)\n",
    "\n",
    "print(len(dataset), len(dataset[0][0]))\n",
    "\n",
    "random.seed(42)\n",
    "random.shuffle(dataset)\n",
    "\n",
    "pleths = []\n",
    "resps = []\n",
    "for ppg, rr in dataset:\n",
    "    pleths.append(ppg.astype(np.float64))\n",
    "    resps.append(rr)\n",
    "\n",
    "pleths = np.asarray(pleths)\n",
    "resps = np.asarray(resps)\n",
    "print(pleths.shape, resps.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6508, 1800, 1) <class 'numpy.float64'>\n",
      "(5206, 1800, 1) (5206,)\n",
      "(1302, 1800, 1) (1302,)\n"
     ]
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "scaled_pleths = np.asarray([scaler.fit_transform(pleth.reshape(-1,1)) for pleth in pleths])\n",
    "print(scaled_pleths.shape, type(scaled_pleths[0][0][0]))\n",
    "\n",
    "ratio_tr = 0.8\n",
    "train_x, train_y = scaled_pleths[:int(len(scaled_pleths)*ratio_tr)], resps[:int(len(resps)*ratio_tr)]\n",
    "val_x, val_y = scaled_pleths[int(len(scaled_pleths)*ratio_tr):], resps[int(len(resps)*ratio_tr):]\n",
    "print(train_x.shape, train_y.shape)\n",
    "print(val_x.shape, val_y.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Architecture: ResNet 34 Layer\n",
    "\n",
    "- ResNet 모델 구조는 [논문](https://arxiv.org/pdf/1512.03385.pdf)을 참고하였다. 다만 해당 논문은 ImageNet의 데이터를 실행시키기 위한 것으로 조금의 조정이 필요한데 이를 변경하였을 때 그 내용을 논문에 기재할 필요가 있는지 의문이다.\n",
    "- 또는 만약 기재해야 한다면 내가 전부터 참고했던 [Bian의 논문](https://ieeexplore.ieee.org/document/9176231)을 참고해도 될 것 같다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-25 11:01:14.033905: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-05-25 11:01:14.075017: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-25 11:01:14.731097: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is GPU Avaliable: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras.models import Model\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.layers import Conv1D, MaxPooling1D, AveragePooling1D, Dense, BatchNormalization, Activation, Add, Flatten, Dropout\n",
    "print(f'Is GPU Avaliable: {tf.config.list_physical_devices(\"GPU\")}')\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(Model):\n",
    "    def __init__(self, filters, kernel_size, strides, identity_mapping=None, *args, **kwargs):\n",
    "        super(ResidualBlock, self).__init__(*args, **kwargs)\n",
    "        self.conv1 = Conv1D(filters=filters, kernel_size=kernel_size, strides=strides[0], padding='same', kernel_initializer='HeUniform')\n",
    "        self.bn1 = BatchNormalization()\n",
    "\n",
    "        self.conv2 = Conv1D(filters=filters, kernel_size=kernel_size, strides=strides[1], padding='same', kernel_initializer='HeUniform')\n",
    "        self.bn2 = BatchNormalization()\n",
    "\n",
    "        self.identity_mapping = identity_mapping\n",
    "        self.conv_identity = Conv1D(filters=filters, kernel_size=1, strides=strides[0], padding='same', kernel_initializer='HeUniform')\n",
    "        \n",
    "\n",
    "    def call(self, inputs, training=None, mask=None):\n",
    "        identity = inputs\n",
    "        x = self.conv1(inputs)\n",
    "        x = self.bn1(x, training=training)\n",
    "        x = Activation('relu')(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x, training=training)\n",
    "\n",
    "        # 448, 64 / 224, 128\n",
    "        if self.identity_mapping:\n",
    "            identity = self.conv_identity(inputs)\n",
    "            # print(inputs.shape, identity.shape)\n",
    "\n",
    "        x = Add()([x, identity])\n",
    "        return Activation('relu')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet34(Model):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(ResNet34, self).__init__(*args, **kwargs)\n",
    "        # self.conv1 = Conv1D(filters=64, kernel_size=7, strides=2)\n",
    "        # self.max1d = MaxPooling1D(pool_size=3, strides=2)\n",
    "        self.resnet_block1 = [ResidualBlock(64, 3, (1,1)) for i in range(3)]\n",
    "        \n",
    "        self.resnet_block2_entry = ResidualBlock(128, 3, (2,1), identity_mapping=True)\n",
    "        self.resnet_block2 = [ResidualBlock(128, 3, (1,1)) for i in range(3)]\n",
    "\n",
    "        self.resnet_block3_entry = ResidualBlock(256, 3, (2,1), identity_mapping=True)\n",
    "        self.resnet_block3 = [ResidualBlock(256, 3, (1,1)) for i in range(5)]\n",
    "\n",
    "        self.resnet_block4_entry = ResidualBlock(512, 3, (2,1), identity_mapping=True)\n",
    "        self.resnet_block4 = [ResidualBlock(512, 3, (1,1)) for i in range(2)]\n",
    "\n",
    "        self.avg1d = AveragePooling1D(pool_size=2, strides=2, padding='same')\n",
    "        self.max1d = MaxPooling1D(pool_size=3, strides=2, padding='same')\n",
    "        self.flatten = Flatten()\n",
    "        self.d100 = Dense(100, activation='relu')\n",
    "        self.d50 = Dense(50, activation='relu')\n",
    "        self.d10 = Dense(10, activation='relu')\n",
    "        self.d1 = Dense(1)\n",
    "\n",
    "    \n",
    "    def call(self, inputs, training=None, mask=None):\n",
    "        # x = self.conv1(inputs)\n",
    "        # x = self.max1d(x)\n",
    "\n",
    "        x = inputs\n",
    "        for block in self.resnet_block1:\n",
    "            x = block(x, training=training)\n",
    "\n",
    "        x = self.resnet_block2_entry(x, training=training)\n",
    "        for block in self.resnet_block2:\n",
    "            x = block(x, training=training)\n",
    "\n",
    "        x = self.resnet_block3_entry(x, training=training)\n",
    "        for block in self.resnet_block3:\n",
    "            x = block(x, training=training)\n",
    "        \n",
    "        x = self.resnet_block4_entry(x, training=training)\n",
    "        for block in self.resnet_block4:\n",
    "            x = block(x, training=training)\n",
    "        \n",
    "        \n",
    "        x = self.avg1d(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.d100(x)\n",
    "        x = self.d50(x)\n",
    "        x = self.d10(x)\n",
    "        return self.d1(x)\n",
    "    \n",
    "    @tf.function\n",
    "    def train_step(self, data):\n",
    "        x, y = data\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred = self(x, training=True)\n",
    "            loss = self.compiled_loss(y, y_pred)\n",
    "\n",
    "        gradients = tape.gradient(loss, self.trainable_variables)\n",
    "        self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\n",
    "        self.compiled_metrics.update_state(y, y_pred)\n",
    "\n",
    "        return {m.name: m.result() for m in self.metrics}\n",
    "    \n",
    "    @tf.function\n",
    "    def test_step(self, data):\n",
    "        x, y = data\n",
    "\n",
    "        y_pred = self(x, training=False)\n",
    "        self.compiled_loss(y, y_pred)\n",
    "        self.compiled_metrics.update_state(y, y_pred)\n",
    "        return {m.name: m.result() for m in self.metrics}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ResNet34' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 11\u001b[0m\n\u001b[1;32m      4\u001b[0m kf \u001b[39m=\u001b[39m KFold(n_splits\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m)\n\u001b[1;32m      5\u001b[0m callbacks \u001b[39m=\u001b[39m [\n\u001b[1;32m      6\u001b[0m     EarlyStopping(monitor\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mval_loss\u001b[39m\u001b[39m'\u001b[39m, patience\u001b[39m=\u001b[39m\u001b[39m15\u001b[39m),\n\u001b[1;32m      7\u001b[0m     ReduceLROnPlateau(monitor\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mval_loss\u001b[39m\u001b[39m'\u001b[39m, factor\u001b[39m=\u001b[39m\u001b[39m0.1\u001b[39m, patience\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m),\n\u001b[1;32m      8\u001b[0m     \u001b[39m# ModelCheckpoint('../models/230522-Resnet', monitor='val_loss', save_best_only=True)\u001b[39;00m\n\u001b[1;32m      9\u001b[0m ]\n\u001b[0;32m---> 11\u001b[0m model \u001b[39m=\u001b[39m ResNet34()\n\u001b[1;32m     12\u001b[0m model\u001b[39m.\u001b[39mcompile(\n\u001b[1;32m     13\u001b[0m     optimizer\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39moptimizers\u001b[39m.\u001b[39mSGD(learning_rate\u001b[39m=\u001b[39mLR, momentum\u001b[39m=\u001b[39m\u001b[39m0.9\u001b[39m, weight_decay\u001b[39m=\u001b[39m\u001b[39m0.0001\u001b[39m),\n\u001b[1;32m     14\u001b[0m     loss\u001b[39m=\u001b[39mkeras\u001b[39m.\u001b[39mlosses\u001b[39m.\u001b[39mMeanAbsoluteError(),\n\u001b[1;32m     15\u001b[0m     metrics\u001b[39m=\u001b[39mkeras\u001b[39m.\u001b[39mmetrics\u001b[39m.\u001b[39mMeanAbsoluteError()\n\u001b[1;32m     16\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ResNet34' is not defined"
     ]
    }
   ],
   "source": [
    "EPOCHS = 1000\n",
    "BATCH_SIZE = 256\n",
    "LR = 0.001\n",
    "kf = KFold(n_splits=5)\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=15),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5),\n",
    "    # ModelCheckpoint('../models/230522-Resnet', monitor='val_loss', save_best_only=True)\n",
    "]\n",
    "\n",
    "model = ResNet34()\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.SGD(learning_rate=LR, momentum=0.9, weight_decay=0.0001),\n",
    "    loss=keras.losses.MeanAbsoluteError(),\n",
    "    metrics=keras.metrics.MeanAbsoluteError()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-25 11:01:33.595992: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14369 MB memory:  -> device: 0, name: Quadro RTX 5000, pci bus id: 0000:73:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_x, train_y)).batch(BATCH_SIZE)\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((val_x, val_y)).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-24 13:51:58.136551: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int64 and shape [5206]\n",
      "\t [[{{node Placeholder/_1}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - ETA: 0s - loss: 20.5604 - mean_absolute_error: 20.5604"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-24 13:52:30.940599: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int64 and shape [1302]\n",
      "\t [[{{node Placeholder/_1}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 35s 1s/step - loss: 20.5604 - mean_absolute_error: 20.5604 - val_loss: 239.7426 - val_mean_absolute_error: 239.7426 - lr: 0.0010\n",
      "Epoch 2/1000\n",
      "21/21 [==============================] - 22s 1s/step - loss: 5.0804 - mean_absolute_error: 5.0804 - val_loss: 81.3533 - val_mean_absolute_error: 81.3533 - lr: 0.0010\n",
      "Epoch 3/1000\n",
      "21/21 [==============================] - 22s 1s/step - loss: 3.5636 - mean_absolute_error: 3.5636 - val_loss: 32.2890 - val_mean_absolute_error: 32.2890 - lr: 0.0010\n",
      "Epoch 4/1000\n",
      "21/21 [==============================] - 22s 1s/step - loss: 3.4099 - mean_absolute_error: 3.4099 - val_loss: 15.7346 - val_mean_absolute_error: 15.7346 - lr: 0.0010\n",
      "Epoch 5/1000\n",
      "21/21 [==============================] - 22s 1s/step - loss: 1.9273 - mean_absolute_error: 1.9273 - val_loss: 12.1972 - val_mean_absolute_error: 12.1972 - lr: 0.0010\n",
      "Epoch 6/1000\n",
      "21/21 [==============================] - 22s 1s/step - loss: 2.5761 - mean_absolute_error: 2.5761 - val_loss: 13.9455 - val_mean_absolute_error: 13.9455 - lr: 0.0010\n",
      "Epoch 7/1000\n",
      "21/21 [==============================] - 22s 1s/step - loss: 4.8633 - mean_absolute_error: 4.8633 - val_loss: 6.5904 - val_mean_absolute_error: 6.5904 - lr: 0.0010\n",
      "Epoch 8/1000\n",
      "21/21 [==============================] - 22s 1s/step - loss: 3.1928 - mean_absolute_error: 3.1928 - val_loss: 4.6580 - val_mean_absolute_error: 4.6580 - lr: 0.0010\n",
      "Epoch 9/1000\n",
      "21/21 [==============================] - 22s 1s/step - loss: 2.6394 - mean_absolute_error: 2.6394 - val_loss: 5.3729 - val_mean_absolute_error: 5.3729 - lr: 0.0010\n",
      "Epoch 10/1000\n",
      "21/21 [==============================] - 22s 1s/step - loss: 1.2885 - mean_absolute_error: 1.2885 - val_loss: 4.4342 - val_mean_absolute_error: 4.4342 - lr: 0.0010\n",
      "Epoch 11/1000\n",
      "21/21 [==============================] - 22s 1s/step - loss: 2.6739 - mean_absolute_error: 2.6739 - val_loss: 4.2690 - val_mean_absolute_error: 4.2690 - lr: 0.0010\n",
      "Epoch 12/1000\n",
      "21/21 [==============================] - 22s 1s/step - loss: 3.3765 - mean_absolute_error: 3.3765 - val_loss: 3.9411 - val_mean_absolute_error: 3.9411 - lr: 0.0010\n",
      "Epoch 13/1000\n",
      "21/21 [==============================] - 22s 1s/step - loss: 6.5592 - mean_absolute_error: 6.5592 - val_loss: 8.0726 - val_mean_absolute_error: 8.0726 - lr: 0.0010\n",
      "Epoch 14/1000\n",
      "21/21 [==============================] - 22s 1s/step - loss: 2.9294 - mean_absolute_error: 2.9294 - val_loss: 6.0277 - val_mean_absolute_error: 6.0277 - lr: 0.0010\n",
      "Epoch 15/1000\n",
      "21/21 [==============================] - 22s 1s/step - loss: 2.3741 - mean_absolute_error: 2.3741 - val_loss: 6.4834 - val_mean_absolute_error: 6.4834 - lr: 0.0010\n",
      "Epoch 16/1000\n",
      "21/21 [==============================] - 22s 1s/step - loss: 2.0869 - mean_absolute_error: 2.0869 - val_loss: 6.1884 - val_mean_absolute_error: 6.1884 - lr: 0.0010\n",
      "Epoch 17/1000\n",
      "21/21 [==============================] - 22s 1s/step - loss: 2.0689 - mean_absolute_error: 2.0689 - val_loss: 7.2717 - val_mean_absolute_error: 7.2717 - lr: 0.0010\n",
      "Epoch 18/1000\n",
      "21/21 [==============================] - 22s 1s/step - loss: 1.3273 - mean_absolute_error: 1.3273 - val_loss: 4.8321 - val_mean_absolute_error: 4.8321 - lr: 1.0000e-04\n",
      "Epoch 19/1000\n",
      "21/21 [==============================] - 22s 1s/step - loss: 0.7849 - mean_absolute_error: 0.7849 - val_loss: 4.0636 - val_mean_absolute_error: 4.0636 - lr: 1.0000e-04\n",
      "Epoch 20/1000\n",
      "21/21 [==============================] - 22s 1s/step - loss: 0.8037 - mean_absolute_error: 0.8037 - val_loss: 3.3833 - val_mean_absolute_error: 3.3833 - lr: 1.0000e-04\n",
      "Epoch 21/1000\n",
      "21/21 [==============================] - 22s 1s/step - loss: 0.8202 - mean_absolute_error: 0.8202 - val_loss: 2.9078 - val_mean_absolute_error: 2.9078 - lr: 1.0000e-04\n",
      "Epoch 22/1000\n",
      "21/21 [==============================] - 22s 1s/step - loss: 0.7788 - mean_absolute_error: 0.7788 - val_loss: 2.4334 - val_mean_absolute_error: 2.4334 - lr: 1.0000e-04\n",
      "Epoch 23/1000\n",
      "21/21 [==============================] - 22s 1s/step - loss: 0.9298 - mean_absolute_error: 0.9298 - val_loss: 1.9848 - val_mean_absolute_error: 1.9848 - lr: 1.0000e-04\n",
      "Epoch 24/1000\n",
      "21/21 [==============================] - 22s 1s/step - loss: 0.7947 - mean_absolute_error: 0.7947 - val_loss: 1.7562 - val_mean_absolute_error: 1.7562 - lr: 1.0000e-04\n",
      "Epoch 25/1000\n",
      "21/21 [==============================] - 22s 1s/step - loss: 0.9435 - mean_absolute_error: 0.9435 - val_loss: 1.4542 - val_mean_absolute_error: 1.4542 - lr: 1.0000e-04\n",
      "Epoch 26/1000\n",
      "21/21 [==============================] - 22s 1s/step - loss: 0.7800 - mean_absolute_error: 0.7800 - val_loss: 1.3180 - val_mean_absolute_error: 1.3180 - lr: 1.0000e-04\n",
      "Epoch 27/1000\n",
      "21/21 [==============================] - 22s 1s/step - loss: 0.9605 - mean_absolute_error: 0.9605 - val_loss: 1.1829 - val_mean_absolute_error: 1.1829 - lr: 1.0000e-04\n",
      "Epoch 28/1000\n",
      "21/21 [==============================] - 22s 1s/step - loss: 0.7500 - mean_absolute_error: 0.7500 - val_loss: 1.0450 - val_mean_absolute_error: 1.0450 - lr: 1.0000e-04\n",
      "Epoch 29/1000\n",
      "21/21 [==============================] - 22s 1s/step - loss: 0.9941 - mean_absolute_error: 0.9941 - val_loss: 1.0845 - val_mean_absolute_error: 1.0845 - lr: 1.0000e-04\n",
      "Epoch 30/1000\n",
      "21/21 [==============================] - 22s 1s/step - loss: 0.9625 - mean_absolute_error: 0.9625 - val_loss: 0.9982 - val_mean_absolute_error: 0.9982 - lr: 1.0000e-04\n",
      "Epoch 31/1000\n",
      "21/21 [==============================] - 22s 1s/step - loss: 0.6855 - mean_absolute_error: 0.6855 - val_loss: 0.7986 - val_mean_absolute_error: 0.7986 - lr: 1.0000e-04\n",
      "Epoch 32/1000\n",
      "21/21 [==============================] - 22s 1s/step - loss: 0.8477 - mean_absolute_error: 0.8477 - val_loss: 0.9155 - val_mean_absolute_error: 0.9155 - lr: 1.0000e-04\n",
      "Epoch 33/1000\n",
      "21/21 [==============================] - 22s 1s/step - loss: 0.6434 - mean_absolute_error: 0.6434 - val_loss: 0.7138 - val_mean_absolute_error: 0.7138 - lr: 1.0000e-04\n",
      "Epoch 34/1000\n",
      "21/21 [==============================] - 22s 1s/step - loss: 0.8328 - mean_absolute_error: 0.8328 - val_loss: 0.8719 - val_mean_absolute_error: 0.8719 - lr: 1.0000e-04\n",
      "Epoch 35/1000\n",
      "21/21 [==============================] - 22s 1s/step - loss: 0.5924 - mean_absolute_error: 0.5924 - val_loss: 0.7775 - val_mean_absolute_error: 0.7775 - lr: 1.0000e-04\n",
      "Epoch 36/1000\n",
      "21/21 [==============================] - 22s 1s/step - loss: 0.9329 - mean_absolute_error: 0.9329 - val_loss: 0.9879 - val_mean_absolute_error: 0.9879 - lr: 1.0000e-04\n",
      "Epoch 37/1000\n",
      "21/21 [==============================] - 22s 1s/step - loss: 0.6499 - mean_absolute_error: 0.6499 - val_loss: 0.6348 - val_mean_absolute_error: 0.6348 - lr: 1.0000e-04\n",
      "Epoch 38/1000\n",
      "21/21 [==============================] - 22s 1s/step - loss: 0.7628 - mean_absolute_error: 0.7628 - val_loss: 0.8397 - val_mean_absolute_error: 0.8397 - lr: 1.0000e-04\n",
      "Epoch 39/1000\n",
      "21/21 [==============================] - 22s 1s/step - loss: 0.6394 - mean_absolute_error: 0.6394 - val_loss: 0.6383 - val_mean_absolute_error: 0.6383 - lr: 1.0000e-04\n",
      "Epoch 40/1000\n",
      "21/21 [==============================] - 22s 1s/step - loss: 0.7562 - mean_absolute_error: 0.7562 - val_loss: 0.7189 - val_mean_absolute_error: 0.7189 - lr: 1.0000e-04\n",
      "Epoch 41/1000\n",
      "21/21 [==============================] - 22s 1s/step - loss: 0.5113 - mean_absolute_error: 0.5113 - val_loss: 0.7849 - val_mean_absolute_error: 0.7849 - lr: 1.0000e-04\n",
      "Epoch 42/1000\n",
      "21/21 [==============================] - 22s 1s/step - loss: 0.8588 - mean_absolute_error: 0.8588 - val_loss: 0.9195 - val_mean_absolute_error: 0.9195 - lr: 1.0000e-04\n",
      "Epoch 43/1000\n",
      "21/21 [==============================] - 22s 1s/step - loss: 0.8939 - mean_absolute_error: 0.8939 - val_loss: 0.9078 - val_mean_absolute_error: 0.9078 - lr: 1.0000e-05\n",
      "Epoch 44/1000\n",
      "21/21 [==============================] - 22s 1s/step - loss: 0.4790 - mean_absolute_error: 0.4790 - val_loss: 0.7102 - val_mean_absolute_error: 0.7102 - lr: 1.0000e-05\n",
      "Epoch 45/1000\n",
      "21/21 [==============================] - 22s 1s/step - loss: 0.4642 - mean_absolute_error: 0.4642 - val_loss: 0.6302 - val_mean_absolute_error: 0.6302 - lr: 1.0000e-05\n",
      "Epoch 46/1000\n",
      "21/21 [==============================] - 22s 1s/step - loss: 0.4707 - mean_absolute_error: 0.4707 - val_loss: 0.6146 - val_mean_absolute_error: 0.6146 - lr: 1.0000e-05\n",
      "Epoch 47/1000\n",
      "21/21 [==============================] - 22s 1s/step - loss: 0.4732 - mean_absolute_error: 0.4732 - val_loss: 0.6102 - val_mean_absolute_error: 0.6102 - lr: 1.0000e-05\n",
      "Epoch 48/1000\n",
      "21/21 [==============================] - 22s 1s/step - loss: 0.4711 - mean_absolute_error: 0.4711 - val_loss: 0.6080 - val_mean_absolute_error: 0.6080 - lr: 1.0000e-05\n",
      "Epoch 49/1000\n",
      "21/21 [==============================] - 22s 1s/step - loss: 0.4668 - mean_absolute_error: 0.4668 - val_loss: 0.6078 - val_mean_absolute_error: 0.6078 - lr: 1.0000e-05\n",
      "Epoch 50/1000\n",
      "21/21 [==============================] - 22s 1s/step - loss: 0.4624 - mean_absolute_error: 0.4624 - val_loss: 0.6066 - val_mean_absolute_error: 0.6066 - lr: 1.0000e-05\n",
      "Epoch 51/1000\n",
      "21/21 [==============================] - 22s 1s/step - loss: 0.4586 - mean_absolute_error: 0.4586 - val_loss: 0.6059 - val_mean_absolute_error: 0.6059 - lr: 1.0000e-05\n",
      "Epoch 52/1000\n",
      "21/21 [==============================] - 22s 1s/step - loss: 0.4551 - mean_absolute_error: 0.4551 - val_loss: 0.6049 - val_mean_absolute_error: 0.6049 - lr: 1.0000e-05\n",
      "Epoch 53/1000\n",
      "21/21 [==============================] - 22s 1s/step - loss: 0.4524 - mean_absolute_error: 0.4524 - val_loss: 0.6048 - val_mean_absolute_error: 0.6048 - lr: 1.0000e-05\n",
      "Epoch 54/1000\n",
      "21/21 [==============================] - 22s 1s/step - loss: 0.4500 - mean_absolute_error: 0.4500 - val_loss: 0.6045 - val_mean_absolute_error: 0.6045 - lr: 1.0000e-05\n",
      "Epoch 55/1000\n",
      "21/21 [==============================] - 22s 1s/step - loss: 0.4465 - mean_absolute_error: 0.4465 - val_loss: 0.6025 - val_mean_absolute_error: 0.6025 - lr: 1.0000e-05\n",
      "Epoch 56/1000\n",
      "21/21 [==============================] - 22s 1s/step - loss: 0.4434 - mean_absolute_error: 0.4434 - val_loss: 0.6042 - val_mean_absolute_error: 0.6042 - lr: 1.0000e-05\n",
      "Epoch 57/1000\n",
      "21/21 [==============================] - 22s 1s/step - loss: 0.4411 - mean_absolute_error: 0.4411 - val_loss: 0.6019 - val_mean_absolute_error: 0.6019 - lr: 1.0000e-05\n",
      "Epoch 58/1000\n",
      "21/21 [==============================] - 22s 1s/step - loss: 0.4384 - mean_absolute_error: 0.4384 - val_loss: 0.6028 - val_mean_absolute_error: 0.6028 - lr: 1.0000e-05\n",
      "Epoch 59/1000\n",
      "21/21 [==============================] - 22s 1s/step - loss: 0.4367 - mean_absolute_error: 0.4367 - val_loss: 0.6022 - val_mean_absolute_error: 0.6022 - lr: 1.0000e-05\n",
      "Epoch 60/1000\n",
      "21/21 [==============================] - 22s 1s/step - loss: 0.4333 - mean_absolute_error: 0.4333 - val_loss: 0.6014 - val_mean_absolute_error: 0.6014 - lr: 1.0000e-05\n",
      "Epoch 61/1000\n",
      "21/21 [==============================] - 22s 1s/step - loss: 0.4308 - mean_absolute_error: 0.4308 - val_loss: 0.6034 - val_mean_absolute_error: 0.6034 - lr: 1.0000e-05\n",
      "Epoch 62/1000\n",
      "21/21 [==============================] - 22s 1s/step - loss: 0.4315 - mean_absolute_error: 0.4315 - val_loss: 0.6001 - val_mean_absolute_error: 0.6001 - lr: 1.0000e-05\n",
      "Epoch 63/1000\n",
      "21/21 [==============================] - 22s 1s/step - loss: 0.4250 - mean_absolute_error: 0.4250 - val_loss: 0.6020 - val_mean_absolute_error: 0.6020 - lr: 1.0000e-05\n",
      "Epoch 64/1000\n",
      "21/21 [==============================] - 22s 1s/step - loss: 0.4256 - mean_absolute_error: 0.4256 - val_loss: 0.6004 - val_mean_absolute_error: 0.6004 - lr: 1.0000e-05\n",
      "Epoch 65/1000\n",
      "21/21 [==============================] - 22s 1s/step - loss: 0.4228 - mean_absolute_error: 0.4228 - val_loss: 0.6002 - val_mean_absolute_error: 0.6002 - lr: 1.0000e-05\n",
      "Epoch 66/1000\n",
      "21/21 [==============================] - 22s 1s/step - loss: 0.4190 - mean_absolute_error: 0.4190 - val_loss: 0.5999 - val_mean_absolute_error: 0.5999 - lr: 1.0000e-05\n",
      "Epoch 67/1000\n",
      "21/21 [==============================] - 22s 1s/step - loss: 0.4170 - mean_absolute_error: 0.4170 - val_loss: 0.6021 - val_mean_absolute_error: 0.6021 - lr: 1.0000e-05\n",
      "Epoch 68/1000\n",
      "21/21 [==============================] - 22s 1s/step - loss: 0.4196 - mean_absolute_error: 0.4196 - val_loss: 0.5988 - val_mean_absolute_error: 0.5988 - lr: 1.0000e-05\n",
      "Epoch 69/1000\n",
      "21/21 [==============================] - 22s 1s/step - loss: 0.4142 - mean_absolute_error: 0.4142 - val_loss: 0.5997 - val_mean_absolute_error: 0.5997 - lr: 1.0000e-05\n",
      "Epoch 70/1000\n",
      "21/21 [==============================] - 22s 1s/step - loss: 0.4099 - mean_absolute_error: 0.4099 - val_loss: 0.6000 - val_mean_absolute_error: 0.6000 - lr: 1.0000e-05\n",
      "Epoch 71/1000\n",
      "21/21 [==============================] - 22s 1s/step - loss: 0.4107 - mean_absolute_error: 0.4107 - val_loss: 0.6010 - val_mean_absolute_error: 0.6010 - lr: 1.0000e-05\n",
      "Epoch 72/1000\n",
      "21/21 [==============================] - 22s 1s/step - loss: 0.4129 - mean_absolute_error: 0.4129 - val_loss: 0.5977 - val_mean_absolute_error: 0.5977 - lr: 1.0000e-05\n",
      "Epoch 73/1000\n",
      "21/21 [==============================] - 22s 1s/step - loss: 0.4050 - mean_absolute_error: 0.4050 - val_loss: 0.5993 - val_mean_absolute_error: 0.5993 - lr: 1.0000e-05\n",
      "Epoch 74/1000\n",
      "21/21 [==============================] - 22s 1s/step - loss: 0.4033 - mean_absolute_error: 0.4033 - val_loss: 0.5994 - val_mean_absolute_error: 0.5994 - lr: 1.0000e-05\n",
      "Epoch 75/1000\n",
      "21/21 [==============================] - 22s 1s/step - loss: 0.4041 - mean_absolute_error: 0.4041 - val_loss: 0.6002 - val_mean_absolute_error: 0.6002 - lr: 1.0000e-05\n",
      "Epoch 76/1000\n",
      "21/21 [==============================] - 22s 1s/step - loss: 0.4063 - mean_absolute_error: 0.4063 - val_loss: 0.5973 - val_mean_absolute_error: 0.5973 - lr: 1.0000e-05\n",
      "Epoch 77/1000\n",
      "21/21 [==============================] - 22s 1s/step - loss: 0.4007 - mean_absolute_error: 0.4007 - val_loss: 0.5973 - val_mean_absolute_error: 0.5973 - lr: 1.0000e-05\n",
      "Epoch 78/1000\n",
      "21/21 [==============================] - 22s 1s/step - loss: 0.3948 - mean_absolute_error: 0.3948 - val_loss: 0.5979 - val_mean_absolute_error: 0.5979 - lr: 1.0000e-05\n",
      "Epoch 79/1000\n",
      "21/21 [==============================] - 22s 1s/step - loss: 0.3936 - mean_absolute_error: 0.3936 - val_loss: 0.5996 - val_mean_absolute_error: 0.5996 - lr: 1.0000e-05\n",
      "Epoch 80/1000\n",
      "21/21 [==============================] - 22s 1s/step - loss: 0.3970 - mean_absolute_error: 0.3970 - val_loss: 0.5984 - val_mean_absolute_error: 0.5984 - lr: 1.0000e-05\n",
      "Epoch 81/1000\n",
      "21/21 [==============================] - 22s 1s/step - loss: 0.3976 - mean_absolute_error: 0.3976 - val_loss: 0.5978 - val_mean_absolute_error: 0.5978 - lr: 1.0000e-05\n",
      "Epoch 82/1000\n",
      "21/21 [==============================] - 22s 1s/step - loss: 0.3910 - mean_absolute_error: 0.3910 - val_loss: 0.5959 - val_mean_absolute_error: 0.5959 - lr: 1.0000e-06\n",
      "Epoch 83/1000\n",
      "21/21 [==============================] - 22s 1s/step - loss: 0.3777 - mean_absolute_error: 0.3777 - val_loss: 0.5985 - val_mean_absolute_error: 0.5985 - lr: 1.0000e-06\n",
      "Epoch 84/1000\n",
      "21/21 [==============================] - 22s 1s/step - loss: 0.3742 - mean_absolute_error: 0.3742 - val_loss: 0.5968 - val_mean_absolute_error: 0.5968 - lr: 1.0000e-06\n",
      "Epoch 85/1000\n",
      "21/21 [==============================] - 22s 1s/step - loss: 0.3744 - mean_absolute_error: 0.3744 - val_loss: 0.5964 - val_mean_absolute_error: 0.5964 - lr: 1.0000e-06\n",
      "Epoch 86/1000\n",
      "21/21 [==============================] - 22s 1s/step - loss: 0.3737 - mean_absolute_error: 0.3737 - val_loss: 0.5964 - val_mean_absolute_error: 0.5964 - lr: 1.0000e-06\n",
      "Epoch 87/1000\n",
      "21/21 [==============================] - 22s 1s/step - loss: 0.3734 - mean_absolute_error: 0.3734 - val_loss: 0.5961 - val_mean_absolute_error: 0.5961 - lr: 1.0000e-06\n",
      "Epoch 88/1000\n",
      "21/21 [==============================] - 22s 1s/step - loss: 0.3725 - mean_absolute_error: 0.3725 - val_loss: 0.5952 - val_mean_absolute_error: 0.5952 - lr: 1.0000e-07\n",
      "Epoch 89/1000\n",
      "21/21 [==============================] - 22s 1s/step - loss: 0.3728 - mean_absolute_error: 0.3728 - val_loss: 0.5953 - val_mean_absolute_error: 0.5953 - lr: 1.0000e-07\n",
      "Epoch 90/1000\n",
      "21/21 [==============================] - 22s 1s/step - loss: 0.3726 - mean_absolute_error: 0.3726 - val_loss: 0.5953 - val_mean_absolute_error: 0.5953 - lr: 1.0000e-07\n",
      "Epoch 91/1000\n",
      "21/21 [==============================] - 22s 1s/step - loss: 0.3723 - mean_absolute_error: 0.3723 - val_loss: 0.5954 - val_mean_absolute_error: 0.5954 - lr: 1.0000e-07\n",
      "Epoch 92/1000\n",
      "21/21 [==============================] - 22s 1s/step - loss: 0.3722 - mean_absolute_error: 0.3722 - val_loss: 0.5954 - val_mean_absolute_error: 0.5954 - lr: 1.0000e-07\n",
      "Epoch 93/1000\n",
      "21/21 [==============================] - 22s 1s/step - loss: 0.3720 - mean_absolute_error: 0.3720 - val_loss: 0.5954 - val_mean_absolute_error: 0.5954 - lr: 1.0000e-07\n",
      "Epoch 94/1000\n",
      "21/21 [==============================] - 22s 1s/step - loss: 0.3719 - mean_absolute_error: 0.3719 - val_loss: 0.5954 - val_mean_absolute_error: 0.5954 - lr: 1.0000e-08\n",
      "Epoch 95/1000\n",
      "21/21 [==============================] - 22s 1s/step - loss: 0.3719 - mean_absolute_error: 0.3719 - val_loss: 0.5954 - val_mean_absolute_error: 0.5954 - lr: 1.0000e-08\n",
      "Epoch 96/1000\n",
      "21/21 [==============================] - 22s 1s/step - loss: 0.3719 - mean_absolute_error: 0.3719 - val_loss: 0.5954 - val_mean_absolute_error: 0.5954 - lr: 1.0000e-08\n",
      "Epoch 97/1000\n",
      "21/21 [==============================] - 22s 1s/step - loss: 0.3719 - mean_absolute_error: 0.3719 - val_loss: 0.5954 - val_mean_absolute_error: 0.5954 - lr: 1.0000e-08\n",
      "Epoch 98/1000\n",
      "21/21 [==============================] - 22s 1s/step - loss: 0.3719 - mean_absolute_error: 0.3719 - val_loss: 0.5954 - val_mean_absolute_error: 0.5954 - lr: 1.0000e-08\n",
      "Epoch 99/1000\n",
      "21/21 [==============================] - 22s 1s/step - loss: 0.3719 - mean_absolute_error: 0.3719 - val_loss: 0.5954 - val_mean_absolute_error: 0.5954 - lr: 1.0000e-09\n",
      "Epoch 100/1000\n",
      "21/21 [==============================] - 22s 1s/step - loss: 0.3719 - mean_absolute_error: 0.3719 - val_loss: 0.5954 - val_mean_absolute_error: 0.5954 - lr: 1.0000e-09\n",
      "Epoch 101/1000\n",
      "21/21 [==============================] - 22s 1s/step - loss: 0.3719 - mean_absolute_error: 0.3719 - val_loss: 0.5954 - val_mean_absolute_error: 0.5954 - lr: 1.0000e-09\n",
      "Epoch 102/1000\n",
      "21/21 [==============================] - 22s 1s/step - loss: 0.3719 - mean_absolute_error: 0.3719 - val_loss: 0.5954 - val_mean_absolute_error: 0.5954 - lr: 1.0000e-09\n",
      "Epoch 103/1000\n",
      "21/21 [==============================] - 22s 1s/step - loss: 0.3719 - mean_absolute_error: 0.3719 - val_loss: 0.5954 - val_mean_absolute_error: 0.5954 - lr: 1.0000e-09\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/GPU:0'):\n",
    "    history = model.fit(\n",
    "        train_dataset,\n",
    "        epochs=EPOCHS,\n",
    "        callbacks=callbacks,\n",
    "        validation_data=val_dataset\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5952494144439697"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(history.history['val_loss'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Importing a function (__inference_internal_grad_fn_1200144) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n"
     ]
    }
   ],
   "source": [
    "resnet = tf.keras.models.load_model('../models/230522-Resnet/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_x, train_y)).batch(256)\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((val_x, val_y)).batch(256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/6 [====>.........................] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-25 11:05:03.608930: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int64 and shape [1302]\n",
      "\t [[{{node Placeholder/_1}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 2s 319ms/step\n",
      "(1302, 1) (1302,)\n",
      "0.5519124542330084 ± 0.4350521281922736\n"
     ]
    }
   ],
   "source": [
    "pred_y = resnet.predict(val_dataset)\n",
    "print(pred_y.shape, val_y.shape)\n",
    "abs_err = abs(val_y.reshape(-1,1) - pred_y)\n",
    "print(f'{np.mean(abs_err)} ± {np.std(abs_err)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-22 14:54:20.241274: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int64 and shape [1302]\n",
      "\t [[{{node Placeholder/_1}}]]\n",
      "2023-05-22 14:54:21.707843: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 5s 275ms/step - loss: 0.5519 - mean_absolute_error: 0.5519\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5519124865531921, 0.5519124865531921]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet.evaluate(val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 2s 40ms/step\n"
     ]
    }
   ],
   "source": [
    "pred_y = resnet.predict(val_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,7))\n",
    "plt.hist(val_y, bins=15, color='r', density=True, alpha=0.5, label='true resp')\n",
    "plt.hist(pred_y, bins=15, color='b', density=True, alpha=0.5, label='pred resp')\n",
    "plt.axvline(val_y.mean(), color='magenta', linestyle='--', linewidth=3, alpha=.5)\n",
    "plt.axvline(pred_y.mean(), color='cyan', linestyle='--', linewidth=3, alpha=.5)\n",
    "plt.xlabel('Respiratory Rate per min')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,7))\n",
    "plt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BartlettResult(statistic=0.05017061662841224, pvalue=0.8227666536957075)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.bartlett(val_y, pred_y.reshape(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=array([0.17826255], dtype=float32), pvalue=array([0.85853064], dtype=float32))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.ttest_ind(val_y, pred_y, equal_var=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그러므로 ResNet 모델은 실제 호흡수 값들의 평균에 근사한 예측 호흡수 값 평균을 가진다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
