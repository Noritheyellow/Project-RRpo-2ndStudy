{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import multiprocessing\n",
    "from scipy import signal\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "DATA_PATH = '../../DataLake/Capnobase/data/csv'\n",
    "DATA_SAVE_PATH = '/root/Workspace/Project-RRpo-2ndStudy/dataset' \n",
    "regex_capno = re.compile('[0-9]{4}_8min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolation(x, input):\n",
    "    x0 = int(np.floor(x))\n",
    "    y0 = input[x0]\n",
    "    x1 = int(np.ceil(x))\n",
    "    y1 = input[x1]\n",
    "    y = (y1-y0)*(x-x0) + y0\n",
    "    return y\n",
    "\n",
    "\n",
    "def signal_resample(input_signal, org_fs, new_fs, method='interpolation'):\n",
    "    output_signal = []\n",
    "    new_x = np.arange(0, len(input_signal), org_fs/new_fs)\n",
    "    \n",
    "    if method == 'interpolation': \n",
    "        interp = interpolation\n",
    "\n",
    "    for x in new_x:\n",
    "        y = interp(x, input_signal)\n",
    "        output_signal.append(y)\n",
    "\n",
    "    return np.asarray(output_signal)\n",
    "\n",
    "\n",
    "def generate_dataset(arg_pleth, arg_resp, org_fs=125, new_fs=30, shift_factor=4):\n",
    "    window_size = org_fs * 60 # 18000\n",
    "    shift = int(window_size/shift_factor) # 300\n",
    "    shift_n_times = int((len(arg_pleth)-window_size)/shift)+1\n",
    "\n",
    "    window_pleth = np.array([arg_pleth[0+shift*i:window_size+shift*i] for i in range(shift_n_times)])\n",
    "    window_rsmp_pleth = np.array([signal_resample(win, org_fs, new_fs) for win in window_pleth])\n",
    "    window_resp = np.array([round(np.mean(arg_resp.loc[(arg_resp['resp_x']>=(0+(shift//org_fs)*i)) & (arg_resp['resp_x']<(window_size//org_fs) + (shift//org_fs)*i)]['resp_y'].values)) for i in range(shift_n_times)])\n",
    "    dataset = np.array([np.array([window_rsmp_pleth[i], window_resp[i]]) for i in range(len(window_rsmp_pleth))])\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def preprocessing(filepath, id, numtaps, cutoff, shift_factor, org_fs, new_fs):\n",
    "    pleth = pd.read_csv(f'{filepath}/{id}_signal.csv', usecols=['pleth_y'])['pleth_y'].values\n",
    "    resp_x = np.asarray(pd.read_csv(f'{filepath}/{id}_reference.csv')['rr_co2_x'][0].strip().split(' ')).reshape(-1,1)\n",
    "    resp_y = np.asarray(pd.read_csv(f'{filepath}/{id}_reference.csv')['rr_co2_y'][0].strip().split(' ')).reshape(-1,1)\n",
    "    resp = np.concatenate((resp_x, resp_y), axis=1)\n",
    "    resp = pd.DataFrame(resp, columns=['resp_x', 'resp_y'], dtype=np.float32)\n",
    "\n",
    "    taps = signal.firwin(numtaps=numtaps, cutoff=cutoff, window='hamming', pass_zero=False, fs=org_fs)\n",
    "    filtered_pleth = signal.filtfilt(taps, 1.0, pleth)  \n",
    "\n",
    "    dataset = generate_dataset(filtered_pleth, resp, org_fs=org_fs, new_fs=new_fs, shift_factor=shift_factor)\n",
    "    print(f'{id} --> {dataset.shape}')\n",
    "    return id, dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "capno_id = sorted(list(set([regex_capno.match(filename.name).group() for filename in os.scandir(DATA_PATH)])))\n",
    "len(capno_id)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adult Only\n",
    "- 13 ID is upper 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_capno_id = []\n",
    "for id in capno_id:\n",
    "    subject_age = pd.read_csv(f'{DATA_PATH}/{id}_meta.csv', usecols=['subject_age']).values\n",
    "    if subject_age > 18.0:\n",
    "        selected_capno_id.append(id)\n",
    "len(selected_capno_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "capno_meta = pd.concat([pd.read_csv(f'{DATA_PATH}/{id}_meta.csv') for id in selected_capno_id], axis=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process\n",
    "- resp_x 는 초 단위 추정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1805740/1750040665.py:32: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  dataset = np.array([np.array([window_rsmp_pleth[i], window_resp[i]]) for i in range(len(window_rsmp_pleth))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0313_8min --> (421, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1805740/1750040665.py:32: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  dataset = np.array([np.array([window_rsmp_pleth[i], window_resp[i]]) for i in range(len(window_rsmp_pleth))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0309_8min --> (421, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1805740/1750040665.py:32: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  dataset = np.array([np.array([window_rsmp_pleth[i], window_resp[i]]) for i in range(len(window_rsmp_pleth))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0311_8min --> (421, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1805740/1750040665.py:32: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  dataset = np.array([np.array([window_rsmp_pleth[i], window_resp[i]]) for i in range(len(window_rsmp_pleth))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0331_8min --> (421, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1805740/1750040665.py:32: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  dataset = np.array([np.array([window_rsmp_pleth[i], window_resp[i]]) for i in range(len(window_rsmp_pleth))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0325_8min --> (421, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1805740/1750040665.py:32: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  dataset = np.array([np.array([window_rsmp_pleth[i], window_resp[i]]) for i in range(len(window_rsmp_pleth))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0328_8min --> (421, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1805740/1750040665.py:32: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  dataset = np.array([np.array([window_rsmp_pleth[i], window_resp[i]]) for i in range(len(window_rsmp_pleth))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0370_8min --> (421, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1805740/1750040665.py:32: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  dataset = np.array([np.array([window_rsmp_pleth[i], window_resp[i]]) for i in range(len(window_rsmp_pleth))])\n",
      "/tmp/ipykernel_1805740/1750040665.py:32: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  dataset = np.array([np.array([window_rsmp_pleth[i], window_resp[i]]) for i in range(len(window_rsmp_pleth))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0333_8min --> (421, 2)0332_8min --> (421, 2)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1805740/1750040665.py:32: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  dataset = np.array([np.array([window_rsmp_pleth[i], window_resp[i]]) for i in range(len(window_rsmp_pleth))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0329_8min --> (421, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1805740/1750040665.py:32: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  dataset = np.array([np.array([window_rsmp_pleth[i], window_resp[i]]) for i in range(len(window_rsmp_pleth))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0330_8min --> (421, 2)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1805740/1750040665.py:32: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  dataset = np.array([np.array([window_rsmp_pleth[i], window_resp[i]]) for i in range(len(window_rsmp_pleth))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0322_8min --> (421, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1805740/1750040665.py:32: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  dataset = np.array([np.array([window_rsmp_pleth[i], window_resp[i]]) for i in range(len(window_rsmp_pleth))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0312_8min --> (421, 2)\n"
     ]
    }
   ],
   "source": [
    "pool = multiprocessing.Pool(processes=40)\n",
    "results = pool.starmap(preprocessing, [(DATA_PATH, pid, 2000, [0.1,0.4], 60, 300, 30) for pid in selected_capno_id])\n",
    "pool.close()\n",
    "pool.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1805740/1211627134.py:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  np.save(f'{DATA_SAVE_PATH}/230920/capno-preprocessed.npy', np.array(results))\n"
     ]
    }
   ],
   "source": [
    "np.save(f'{DATA_SAVE_PATH}/230920/capno-preprocessed.npy', np.array(results))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 호흡에 따른 데이터 분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13, 2)\n"
     ]
    }
   ],
   "source": [
    "dataset = np.load(f'{DATA_SAVE_PATH}/230920/capno-preprocessed.npy', allow_pickle=True)\n",
    "print(dataset.shape) # (subject_id, (pleth, resp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5473"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = 0\n",
    "for id, samples in dataset:\n",
    "    count += len(samples)\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 4 8\n"
     ]
    }
   ],
   "source": [
    "fast_id = []; normal_id = []; slow_id = []\n",
    "for sample in dataset:\n",
    "    pid = sample[0]\n",
    "    mean_resp = np.mean([resp for _, resp in sample[1]])\n",
    "    \n",
    "    if mean_resp < 12: slow_id.append(pid)\n",
    "    elif mean_resp > 18: fast_id.append(pid)\n",
    "    else: normal_id.append(pid)\n",
    "\n",
    "print(len(fast_id), len(normal_id), len(slow_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 4 8\n"
     ]
    }
   ],
   "source": [
    "fast_dataset = []; normal_dataset = []; slow_dataset = []\n",
    "for sample in dataset:\n",
    "    if sample[0] in fast_id:\n",
    "        fast_dataset.append(sample)\n",
    "    elif sample[0] in slow_id:\n",
    "        slow_dataset.append(sample)\n",
    "    else:\n",
    "        normal_dataset.append(sample)\n",
    "print(len(fast_dataset), len(normal_dataset), len(slow_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(f'{DATA_SAVE_PATH}/230920/capno-preprocessed_fastRR.npy', np.array(fast_dataset))\n",
    "np.save(f'{DATA_SAVE_PATH}/230920/capno-preprocessed_normalRR.npy', np.array(normal_dataset))\n",
    "np.save(f'{DATA_SAVE_PATH}/230920/capno-preprocessed_slowRR.npy', np.array(slow_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(144001,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## ARCHIVE\n",
    "# pleth = pd.read_csv(f'{DATA_PATH}/{selected_capno_id[0]}_signal.csv', usecols=['pleth_y'])['pleth_y'].values\n",
    "# resp_x = np.asarray(pd.read_csv(f'{DATA_PATH}/{selected_capno_id[0]}_reference.csv')['rr_co2_x'][0].strip().split(' ')).reshape(-1,1)\n",
    "# resp_y = np.asarray(pd.read_csv(f'{DATA_PATH}/{selected_capno_id[0]}_reference.csv')['rr_co2_y'][0].strip().split(' ')).reshape(-1,1)\n",
    "# resp = np.concatenate((resp_x, resp_y), axis=1)\n",
    "# resp = pd.DataFrame(resp, columns=['resp_x', 'resp_y'], dtype=np.float32)\n",
    "\n",
    "# taps = signal.firwin(numtaps=2000, cutoff=[0.1,0.4], window='hamming', pass_zero=False, fs=300)\n",
    "# filtered_pleth = signal.filtfilt(taps, 1.0, pleth)\n",
    "# filtered_pleth.shape\n",
    "\n",
    "# org_fs = 300\n",
    "# new_fs = 30\n",
    "# shift_factor = 60\n",
    "# window_size = org_fs * 60 # 18000\n",
    "# shift = int(window_size/shift_factor) # 300\n",
    "# shift_n_times = int((len(pleth)-window_size)/shift)+1\n",
    "\n",
    "# window_pleth = np.array([pleth[0+shift*i:window_size+shift*i] for i in range(shift_n_times)])\n",
    "# window_rsmp_pleth = np.array([signal_resample(win, org_fs, new_fs) for win in window_pleth])\n",
    "# window_resp = np.array([round(np.mean(resp.loc[(resp['resp_x']>=(0+(shift//org_fs)*i)) & (resp['resp_x']<(window_size//org_fs) + (shift//org_fs)*i)]['resp_y'].values)) for i in range(shift_n_times)])\n",
    "# window_pleth.shape, window_rsmp_pleth.shape, window_resp.shape\n",
    "\n",
    "# dataset = np.array([np.array([window_rsmp_pleth[i], window_resp[i]]) for i in range(len(window_rsmp_pleth))])\n",
    "# dataset.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
