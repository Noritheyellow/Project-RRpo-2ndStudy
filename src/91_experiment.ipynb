{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-31 14:53:34.258683: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-05-31 14:53:34.304922: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-31 14:53:35.002142: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import multiprocessing\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from scipy import signal\n",
    "from itertools import starmap\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from models.Resnet import ResNet34\n",
    "from models.Unet import Unet\n",
    "from models.DilatedConv import RespDNN\n",
    "from models.BianResnet import ResNet\n",
    "\n",
    "DATA_PATH = '../../DataLake/stMary'\n",
    "kf = KFold(n_splits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dataset(arg_pleths, arg_resps, fs=125, shift_factor=4):\n",
    "    import copy\n",
    "    dataset = []\n",
    "    window_size = fs * 60 # 7500\n",
    "    shift = int(window_size/shift_factor) # 1875\n",
    "    samples_len = len(arg_pleths)\n",
    "\n",
    "    cpy_resps = copy.deepcopy(arg_resps)\n",
    "    cpy_pleths = copy.deepcopy(arg_pleths)\n",
    "\n",
    "    for i in range(samples_len):\n",
    "        rr = cpy_resps[i]; ppg = cpy_pleths[i]\n",
    "\n",
    "        rr['offset'] = (rr['offset']-rr['offset'].min())/1000\n",
    "        size_lim = int(fs * np.ceil(rr['offset'].max()))\n",
    "        ppg = ppg[:size_lim]\n",
    "        shift_n_times = int((len(ppg)-window_size)/shift)+1\n",
    "\n",
    "        samp_rr = [len(rr.loc[ (rr['offset']>=0+(int(shift/fs)*i)) & ((rr['offset']<int(window_size/fs)+(int(shift/fs)*i))) ]) for i in range(shift_n_times)]\n",
    "        samp_ppg = [ppg[0+(shift*i):window_size+(shift*i)] for i in range(shift_n_times)]\n",
    "\n",
    "        for i in range(len(samp_ppg)):\n",
    "            temp = []\n",
    "            temp.append(samp_ppg[i])\n",
    "            temp.append(samp_rr[i])\n",
    "            dataset.append(temp)\n",
    "\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def interpolation(x, input):\n",
    "    x0 = int(np.floor(x))\n",
    "    y0 = input[x0]\n",
    "    x1 = int(np.ceil(x))\n",
    "    y1 = input[x1]\n",
    "    y = (y1-y0)*(x-x0) + y0\n",
    "    return y\n",
    "\n",
    "\n",
    "def signal_resample(input_signal, org_fs, new_fs, method='interpolation'):\n",
    "    output_signal = []\n",
    "    new_x = np.arange(0, len(input_signal), org_fs/new_fs)\n",
    "    \n",
    "    if method == 'interpolation': \n",
    "        interp = interpolation\n",
    "\n",
    "    for x in new_x:\n",
    "        y = interp(x, input_signal)\n",
    "        output_signal.append(y)\n",
    "\n",
    "    return np.asarray(output_signal)\n",
    "\n",
    "\n",
    "def preprocessing(targets=None):\n",
    "    print('Extract PLETH/RESP')\n",
    "    pleths = [pd.read_csv(f'{DATA_PATH}/{sid}/pleth.csv', header=None, names=['sid', 'offset', 'pleth']).pleth.values for sid in targets.id.unique()]\n",
    "    resps = [pd.read_csv(f'{DATA_PATH}/{sid}/respirationTimeline.csv', header=None, names=['sid', 'offset']) for sid in targets.id.unique()]\n",
    "\n",
    "    # Before filtering: Check NaN\n",
    "    for pleth in pleths:\n",
    "        if any(np.isnan(pleth)):\n",
    "            print('check')\n",
    "\n",
    "    # Before filtering: Convert type as np.int16\n",
    "    pleths = list(map(lambda pleth: pleth.astype(np.int16), pleths))\n",
    "\n",
    "\n",
    "    print('Init Preprocessing: Filtering')\n",
    "    taps = signal.firwin(numtaps=400, cutoff=[0.5, 8.0], window='hamming', pass_zero=False, fs=125)\n",
    "    w, h = signal.freqz(taps)\n",
    "    pool = multiprocessing.Pool(processes=40)\n",
    "    filtered_pleths = pool.starmap(signal.filtfilt, [(taps, 1.0, pleth) for pleth in pleths])\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "\n",
    "\n",
    "    print('Init Preprocessing: Windowing')\n",
    "    dataset = generate_dataset(filtered_pleths, resps, shift_factor=60)\n",
    "\n",
    "\n",
    "    print('Init Preprocessing: Resampling')\n",
    "    pool = multiprocessing.Pool(processes=40)\n",
    "    result = pool.starmap(signal_resample, [(pleth[0], 125, 30) for pleth in dataset])\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "\n",
    "    new_patient = []\n",
    "    for i in range(len(dataset)):\n",
    "        temp = []\n",
    "        temp.append(result[i])\n",
    "        temp.append(dataset[i][1])\n",
    "        new_patient.append(temp)\n",
    "\n",
    "    return new_patient\n",
    "\n",
    "\n",
    "def prepare_modeling(dataset=None, batchsize=None):\n",
    "    print(f'Prepare modeling')\n",
    "    pleths = []\n",
    "    resps = []\n",
    "    for ppg, rr in dataset:\n",
    "        pleths.append(ppg.astype(np.float32))\n",
    "        resps.append(rr)\n",
    "    pleths = np.asarray(pleths)\n",
    "    resps = np.asarray(resps)\n",
    "    print(pleths.shape, resps.shape)\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    scaled_pleths = np.asarray([scaler.fit_transform(pleth.reshape(-1,1)) for pleth in pleths])\n",
    "    print(scaled_pleths.shape, type(scaled_pleths[0][0][0]))\n",
    "\n",
    "    x, y = scaled_pleths[:], resps[:]\n",
    "\n",
    "    return tf.data.Dataset.from_tensor_slices((x, y)).batch(batchsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init Sampling\n",
      "Train-Test Split into 80:20 (Random seed 42)\n",
      "[0, 1, 2, 5, 6, 7, 8, 9, 10, 12, 15, 16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 30, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 55, 56, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 68, 70, 72, 73, 74, 76, 78, 79, 80, 82, 83, 84, 85, 87, 88, 89, 90, 91, 92, 93, 95, 96, 97, 98, 99] [81, 14, 3, 94, 35, 31, 28, 17, 13, 86, 69, 11, 75, 54, 4, 27, 29, 64, 77, 71]\n"
     ]
    }
   ],
   "source": [
    "subjects = pd.read_csv(f'{DATA_PATH}/patients.csv')\n",
    "patients = subjects.loc[subjects['diagnosis']!='0']\n",
    "\n",
    "print('Init Sampling')\n",
    "rand_idx = list(range(100))\n",
    "random.seed(42)\n",
    "test_idx = random.sample(rand_idx, k=20)\n",
    "train_idx = list(set(rand_idx) - set(test_idx))\n",
    "train_patients = patients.iloc[train_idx]\n",
    "test_patients = patients.iloc[test_idx]\n",
    "print('Train-Test Split into 80:20 (Random seed 42)')\n",
    "print(train_idx, test_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 1000\n",
    "BATCH_SIZE = 256\n",
    "LR = 0.001\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=23),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=10)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1th K-fold\n",
      "Extract PLETH/RESP\n",
      "Init Preprocessing: Filtering\n",
      "Init Preprocessing: Windowing\n",
      "Init Preprocessing: Resampling\n",
      "Extract PLETH/RESP\n",
      "Init Preprocessing: Filtering\n",
      "Init Preprocessing: Windowing\n",
      "Init Preprocessing: Resampling\n",
      "Preprocessing finished: 4176 / 1048\n",
      "Prepare modeling\n",
      "(4176, 1800) (4176,)\n",
      "(4176, 1800, 1) <class 'numpy.float32'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-31 14:54:50.299996: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14289 MB memory:  -> device: 0, name: Quadro RTX 5000, pci bus id: 0000:73:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepare modeling\n",
      "(1048, 1800) (1048,)\n",
      "(1048, 1800, 1) <class 'numpy.float32'>\n",
      "2th K-fold\n",
      "Extract PLETH/RESP\n",
      "Init Preprocessing: Filtering\n",
      "Init Preprocessing: Windowing\n",
      "Init Preprocessing: Resampling\n",
      "Extract PLETH/RESP\n",
      "Init Preprocessing: Filtering\n",
      "Init Preprocessing: Windowing\n",
      "Init Preprocessing: Resampling\n",
      "Preprocessing finished: 4157 / 1067\n",
      "Prepare modeling\n",
      "(4157, 1800) (4157,)\n",
      "(4157, 1800, 1) <class 'numpy.float32'>\n",
      "Prepare modeling\n",
      "(1067, 1800) (1067,)\n",
      "(1067, 1800, 1) <class 'numpy.float32'>\n",
      "3th K-fold\n",
      "Extract PLETH/RESP\n",
      "Init Preprocessing: Filtering\n",
      "Init Preprocessing: Windowing\n",
      "Init Preprocessing: Resampling\n",
      "Extract PLETH/RESP\n",
      "Init Preprocessing: Filtering\n",
      "Init Preprocessing: Windowing\n",
      "Init Preprocessing: Resampling\n",
      "Preprocessing finished: 4218 / 1006\n",
      "Prepare modeling\n",
      "(4218, 1800) (4218,)\n",
      "(4218, 1800, 1) <class 'numpy.float32'>\n",
      "Prepare modeling\n",
      "(1006, 1800) (1006,)\n",
      "(1006, 1800, 1) <class 'numpy.float32'>\n",
      "4th K-fold\n",
      "Extract PLETH/RESP\n",
      "Init Preprocessing: Filtering\n",
      "Init Preprocessing: Windowing\n",
      "Init Preprocessing: Resampling\n",
      "Extract PLETH/RESP\n",
      "Init Preprocessing: Filtering\n",
      "Init Preprocessing: Windowing\n",
      "Init Preprocessing: Resampling\n",
      "Preprocessing finished: 4150 / 1074\n",
      "Prepare modeling\n",
      "(4150, 1800) (4150,)\n",
      "(4150, 1800, 1) <class 'numpy.float32'>\n",
      "Prepare modeling\n",
      "(1074, 1800) (1074,)\n",
      "(1074, 1800, 1) <class 'numpy.float32'>\n",
      "5th K-fold\n",
      "Extract PLETH/RESP\n",
      "Init Preprocessing: Filtering\n",
      "Init Preprocessing: Windowing\n",
      "Init Preprocessing: Resampling\n",
      "Extract PLETH/RESP\n",
      "Init Preprocessing: Filtering\n",
      "Init Preprocessing: Windowing\n",
      "Init Preprocessing: Resampling\n",
      "Preprocessing finished: 4195 / 1029\n",
      "Prepare modeling\n",
      "(4195, 1800) (4195,)\n",
      "(4195, 1800, 1) <class 'numpy.float32'>\n",
      "Prepare modeling\n",
      "(1029, 1800) (1029,)\n",
      "(1029, 1800, 1) <class 'numpy.float32'>\n"
     ]
    }
   ],
   "source": [
    "counter = 1\n",
    "dataset = {\n",
    "    'train': [],\n",
    "    'val': []\n",
    "}\n",
    "for train_idx, val_idx in kf.split(train_patients):\n",
    "    print(f'{counter}th K-fold')\n",
    "    counter = counter + 1\n",
    "    # 이렇게 하는 이유는 Train과 Validation을 완벽히 구별시키기 위함이다.\n",
    "    X_train = preprocessing(train_patients.iloc[train_idx])\n",
    "    X_val = preprocessing(train_patients.iloc[val_idx])\n",
    "    print(f'Preprocessing finished: {len(X_train)} / {len(X_val)}')\n",
    "    \n",
    "    train_dataset = prepare_modeling(X_train, batchsize=256)\n",
    "    val_dataset = prepare_modeling(X_val, batchsize=256)\n",
    "\n",
    "    dataset['train'].append(train_dataset)\n",
    "    dataset['val'].append(val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is GPU Avaliable: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras.models import Model\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.layers import Conv1D, MaxPooling1D, AveragePooling1D, Dense, BatchNormalization, Activation, Add, Flatten, Dropout\n",
    "print(f'Is GPU Avaliable: {tf.config.list_physical_devices(\"GPU\")}')\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "class RespBlock(Model):\n",
    "    def __init__(self, filters, *args, **kwargs):\n",
    "        super(RespBlock, self).__init__(*args, **kwargs)\n",
    "        self.conv1 = Conv1D(filters=filters, kernel_size=3, strides=1, dilation_rate=1, padding='same')\n",
    "        self.bn1 = BatchNormalization()\n",
    "        self.conv2 = Conv1D(filters=filters, kernel_size=3, strides=1, dilation_rate=2, padding='same')\n",
    "        self.bn2 = BatchNormalization()\n",
    "        self.conv3 = Conv1D(filters=filters, kernel_size=3, strides=1, dilation_rate=3, padding='same')\n",
    "        self.bn3 = BatchNormalization()\n",
    "        # self.conv4 = Conv1D(filters=filters, kernel_size=3, strides=1, dilation_rate=5, padding='same')\n",
    "        # self.bn4 = BatchNormalization()\n",
    "        self.conv1x1 = Conv1D(filters=filters*2, kernel_size=1, strides=1, padding='same')\n",
    "        self.bn1x1 = BatchNormalization()\n",
    "\n",
    "\n",
    "    def call(self, inputs, training=None, mask=None):\n",
    "        x1 = self.conv1(inputs)\n",
    "        x1 = self.bn1(x1)\n",
    "        x1 = Activation('relu')(x1)\n",
    "        x2 = self.conv2(inputs)\n",
    "        x2 = self.bn2(x2)\n",
    "        x2 = Activation('relu')(x2)\n",
    "        x3 = self.conv3(inputs)\n",
    "        x3 = self.bn3(x3)\n",
    "        x3 = Activation('relu')(x3)\n",
    "        # x4 = self.conv4(inputs)\n",
    "        # x4 = self.bn4(x4)\n",
    "        # x4 = Activation('relu')(x4)\n",
    "\n",
    "        x = Add()([x1, x2, x3])\n",
    "        x = self.conv1x1(x)\n",
    "        x = self.bn1x1(x)\n",
    "\n",
    "        if inputs.shape[-1] != 1:\n",
    "            inputs = tf.reduce_mean(inputs, axis=-1, keepdims=True)\n",
    "           \n",
    "        x = Add()([x, inputs])\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "class RespDNN2(Model):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(RespDNN2, self).__init__(*args, **kwargs)\n",
    "        self.respblk = [RespBlock(32*i) for i in np.arange(1, 4)]\n",
    "        self.dwnsamp = [Conv1D(32*i, kernel_size=3, strides=2, padding='same') for i in np.arange(1, 4)]\n",
    "        self.bn = [BatchNormalization() for _ in range(3)]\n",
    "        self.avgpool = AveragePooling1D(strides=2, padding='valid')\n",
    "        self.dense1 = Dense(1000, activation='relu')\n",
    "        self.dense2 = Dense(100, activation='relu')\n",
    "        self.dense3 = Dense(1)\n",
    "\n",
    "    \n",
    "    def call(self, inputs, training=None, mask=None):\n",
    "        x = inputs\n",
    "        for i in range(3):\n",
    "           x = self.respblk[i](x)\n",
    "           x = self.dwnsamp[i](x)\n",
    "           x = self.bn[i](x)\n",
    "           x = Activation('relu')(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = Flatten()(x)\n",
    "        x = self.dense1(x)\n",
    "        x = self.dense2(x)\n",
    "        x = self.dense3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1th K-fold\n",
      "Epoch 1/1000\n",
      "17/17 [==============================] - 14s 207ms/step - loss: 9.6455 - mean_absolute_error: 9.6455 - val_loss: 13.4138 - val_mean_absolute_error: 13.4138 - lr: 0.0010\n",
      "Epoch 2/1000\n",
      "17/17 [==============================] - 3s 179ms/step - loss: 5.4279 - mean_absolute_error: 5.4279 - val_loss: 15.3055 - val_mean_absolute_error: 15.3055 - lr: 0.0010\n",
      "Epoch 3/1000\n",
      "17/17 [==============================] - 3s 180ms/step - loss: 4.7557 - mean_absolute_error: 4.7557 - val_loss: 15.2962 - val_mean_absolute_error: 15.2962 - lr: 0.0010\n",
      "Epoch 4/1000\n",
      "17/17 [==============================] - 3s 180ms/step - loss: 4.9568 - mean_absolute_error: 4.9568 - val_loss: 13.3236 - val_mean_absolute_error: 13.3236 - lr: 0.0010\n",
      "Epoch 5/1000\n",
      "17/17 [==============================] - 3s 180ms/step - loss: 4.8489 - mean_absolute_error: 4.8489 - val_loss: 3.6077 - val_mean_absolute_error: 3.6077 - lr: 0.0010\n",
      "Epoch 6/1000\n",
      "17/17 [==============================] - 3s 180ms/step - loss: 4.2143 - mean_absolute_error: 4.2143 - val_loss: 5.3182 - val_mean_absolute_error: 5.3182 - lr: 0.0010\n",
      "Epoch 7/1000\n",
      "17/17 [==============================] - 3s 180ms/step - loss: 4.2272 - mean_absolute_error: 4.2272 - val_loss: 3.9875 - val_mean_absolute_error: 3.9875 - lr: 0.0010\n",
      "Epoch 8/1000\n",
      "17/17 [==============================] - 3s 180ms/step - loss: 4.0396 - mean_absolute_error: 4.0396 - val_loss: 3.9590 - val_mean_absolute_error: 3.9590 - lr: 0.0010\n",
      "Epoch 9/1000\n",
      "17/17 [==============================] - 3s 180ms/step - loss: 3.8136 - mean_absolute_error: 3.8136 - val_loss: 9.0355 - val_mean_absolute_error: 9.0355 - lr: 0.0010\n",
      "Epoch 10/1000\n",
      "17/17 [==============================] - 3s 179ms/step - loss: 4.3808 - mean_absolute_error: 4.3808 - val_loss: 10.4817 - val_mean_absolute_error: 10.4817 - lr: 0.0010\n",
      "Epoch 11/1000\n",
      "17/17 [==============================] - 3s 180ms/step - loss: 4.9804 - mean_absolute_error: 4.9804 - val_loss: 3.7663 - val_mean_absolute_error: 3.7663 - lr: 0.0010\n",
      "Epoch 12/1000\n",
      "17/17 [==============================] - 3s 180ms/step - loss: 4.9568 - mean_absolute_error: 4.9568 - val_loss: 4.3111 - val_mean_absolute_error: 4.3111 - lr: 0.0010\n",
      "Epoch 13/1000\n",
      "17/17 [==============================] - 3s 179ms/step - loss: 4.6436 - mean_absolute_error: 4.6436 - val_loss: 4.3943 - val_mean_absolute_error: 4.3943 - lr: 0.0010\n",
      "Epoch 14/1000\n",
      "17/17 [==============================] - 3s 180ms/step - loss: 4.5728 - mean_absolute_error: 4.5728 - val_loss: 5.2104 - val_mean_absolute_error: 5.2104 - lr: 0.0010\n",
      "Epoch 15/1000\n",
      "17/17 [==============================] - 3s 180ms/step - loss: 3.9356 - mean_absolute_error: 3.9356 - val_loss: 4.5256 - val_mean_absolute_error: 4.5256 - lr: 0.0010\n",
      "Epoch 16/1000\n",
      "17/17 [==============================] - 3s 180ms/step - loss: 3.5709 - mean_absolute_error: 3.5709 - val_loss: 6.7278 - val_mean_absolute_error: 6.7278 - lr: 1.0000e-04\n",
      "Epoch 17/1000\n",
      "17/17 [==============================] - 3s 180ms/step - loss: 3.1280 - mean_absolute_error: 3.1280 - val_loss: 7.4892 - val_mean_absolute_error: 7.4892 - lr: 1.0000e-04\n",
      "Epoch 18/1000\n",
      "17/17 [==============================] - 3s 181ms/step - loss: 3.0265 - mean_absolute_error: 3.0265 - val_loss: 7.3713 - val_mean_absolute_error: 7.3713 - lr: 1.0000e-04\n",
      "Epoch 19/1000\n",
      "17/17 [==============================] - 3s 180ms/step - loss: 2.9712 - mean_absolute_error: 2.9712 - val_loss: 8.1630 - val_mean_absolute_error: 8.1630 - lr: 1.0000e-04\n",
      "Epoch 20/1000\n",
      "17/17 [==============================] - 3s 180ms/step - loss: 2.9129 - mean_absolute_error: 2.9129 - val_loss: 8.4447 - val_mean_absolute_error: 8.4447 - lr: 1.0000e-04\n",
      "Epoch 21/1000\n",
      "17/17 [==============================] - 3s 180ms/step - loss: 2.8651 - mean_absolute_error: 2.8651 - val_loss: 8.3364 - val_mean_absolute_error: 8.3364 - lr: 1.0000e-04\n",
      "Epoch 22/1000\n",
      "17/17 [==============================] - 3s 180ms/step - loss: 2.8260 - mean_absolute_error: 2.8260 - val_loss: 7.9746 - val_mean_absolute_error: 7.9746 - lr: 1.0000e-04\n",
      "Epoch 23/1000\n",
      "17/17 [==============================] - 3s 180ms/step - loss: 2.7898 - mean_absolute_error: 2.7898 - val_loss: 8.1681 - val_mean_absolute_error: 8.1681 - lr: 1.0000e-04\n",
      "Epoch 24/1000\n",
      "17/17 [==============================] - 3s 180ms/step - loss: 2.7411 - mean_absolute_error: 2.7411 - val_loss: 7.1210 - val_mean_absolute_error: 7.1210 - lr: 1.0000e-04\n",
      "Epoch 25/1000\n",
      "17/17 [==============================] - 3s 180ms/step - loss: 2.7107 - mean_absolute_error: 2.7107 - val_loss: 7.3128 - val_mean_absolute_error: 7.3128 - lr: 1.0000e-04\n",
      "Epoch 26/1000\n",
      "17/17 [==============================] - 3s 180ms/step - loss: 2.6351 - mean_absolute_error: 2.6351 - val_loss: 6.7676 - val_mean_absolute_error: 6.7676 - lr: 1.0000e-05\n",
      "Epoch 27/1000\n",
      "17/17 [==============================] - 3s 180ms/step - loss: 2.6269 - mean_absolute_error: 2.6269 - val_loss: 6.3102 - val_mean_absolute_error: 6.3102 - lr: 1.0000e-05\n",
      "Epoch 28/1000\n",
      "17/17 [==============================] - 3s 180ms/step - loss: 2.6226 - mean_absolute_error: 2.6226 - val_loss: 5.9759 - val_mean_absolute_error: 5.9759 - lr: 1.0000e-05\n",
      "2th K-fold\n",
      "Epoch 1/1000\n",
      "17/17 [==============================] - 15s 207ms/step - loss: 8.4942 - mean_absolute_error: 8.4942 - val_loss: 9.3915 - val_mean_absolute_error: 9.3915 - lr: 0.0010\n",
      "Epoch 2/1000\n",
      "17/17 [==============================] - 3s 179ms/step - loss: 6.0167 - mean_absolute_error: 6.0167 - val_loss: 10.7887 - val_mean_absolute_error: 10.7887 - lr: 0.0010\n",
      "Epoch 3/1000\n",
      "17/17 [==============================] - 3s 179ms/step - loss: 6.4230 - mean_absolute_error: 6.4230 - val_loss: 9.6478 - val_mean_absolute_error: 9.6478 - lr: 0.0010\n",
      "Epoch 4/1000\n",
      "17/17 [==============================] - 3s 180ms/step - loss: 4.5593 - mean_absolute_error: 4.5593 - val_loss: 5.0147 - val_mean_absolute_error: 5.0147 - lr: 0.0010\n",
      "Epoch 5/1000\n",
      "17/17 [==============================] - 3s 180ms/step - loss: 3.9930 - mean_absolute_error: 3.9930 - val_loss: 4.4790 - val_mean_absolute_error: 4.4790 - lr: 0.0010\n",
      "Epoch 6/1000\n",
      "17/17 [==============================] - 3s 179ms/step - loss: 3.5042 - mean_absolute_error: 3.5042 - val_loss: 10.2266 - val_mean_absolute_error: 10.2266 - lr: 0.0010\n",
      "Epoch 7/1000\n",
      "17/17 [==============================] - 3s 180ms/step - loss: 3.8613 - mean_absolute_error: 3.8613 - val_loss: 4.6774 - val_mean_absolute_error: 4.6774 - lr: 0.0010\n",
      "Epoch 8/1000\n",
      "17/17 [==============================] - 3s 179ms/step - loss: 3.6272 - mean_absolute_error: 3.6272 - val_loss: 4.4227 - val_mean_absolute_error: 4.4227 - lr: 0.0010\n",
      "Epoch 9/1000\n",
      "17/17 [==============================] - 3s 180ms/step - loss: 3.8383 - mean_absolute_error: 3.8383 - val_loss: 7.9733 - val_mean_absolute_error: 7.9733 - lr: 0.0010\n",
      "Epoch 10/1000\n",
      "17/17 [==============================] - 3s 180ms/step - loss: 3.6086 - mean_absolute_error: 3.6086 - val_loss: 8.9333 - val_mean_absolute_error: 8.9333 - lr: 0.0010\n",
      "Epoch 11/1000\n",
      "17/17 [==============================] - 3s 179ms/step - loss: 3.5757 - mean_absolute_error: 3.5757 - val_loss: 4.9593 - val_mean_absolute_error: 4.9593 - lr: 0.0010\n",
      "Epoch 12/1000\n",
      "17/17 [==============================] - 3s 179ms/step - loss: 3.2185 - mean_absolute_error: 3.2185 - val_loss: 7.2576 - val_mean_absolute_error: 7.2576 - lr: 0.0010\n",
      "Epoch 13/1000\n",
      "17/17 [==============================] - 3s 179ms/step - loss: 3.2478 - mean_absolute_error: 3.2478 - val_loss: 11.4180 - val_mean_absolute_error: 11.4180 - lr: 0.0010\n",
      "Epoch 14/1000\n",
      "17/17 [==============================] - 3s 180ms/step - loss: 3.8710 - mean_absolute_error: 3.8710 - val_loss: 7.5072 - val_mean_absolute_error: 7.5072 - lr: 0.0010\n",
      "Epoch 15/1000\n",
      "17/17 [==============================] - 3s 179ms/step - loss: 3.6454 - mean_absolute_error: 3.6454 - val_loss: 8.1734 - val_mean_absolute_error: 8.1734 - lr: 0.0010\n",
      "Epoch 16/1000\n",
      "17/17 [==============================] - 3s 180ms/step - loss: 3.5283 - mean_absolute_error: 3.5283 - val_loss: 6.9538 - val_mean_absolute_error: 6.9538 - lr: 0.0010\n",
      "Epoch 17/1000\n",
      "17/17 [==============================] - 3s 180ms/step - loss: 3.7447 - mean_absolute_error: 3.7447 - val_loss: 9.4798 - val_mean_absolute_error: 9.4798 - lr: 0.0010\n",
      "Epoch 18/1000\n",
      "17/17 [==============================] - 3s 179ms/step - loss: 3.5484 - mean_absolute_error: 3.5484 - val_loss: 10.3280 - val_mean_absolute_error: 10.3280 - lr: 0.0010\n",
      "Epoch 19/1000\n",
      "17/17 [==============================] - 3s 179ms/step - loss: 3.2171 - mean_absolute_error: 3.2171 - val_loss: 9.3210 - val_mean_absolute_error: 9.3210 - lr: 1.0000e-04\n",
      "Epoch 20/1000\n",
      "17/17 [==============================] - 3s 179ms/step - loss: 2.5899 - mean_absolute_error: 2.5899 - val_loss: 8.1979 - val_mean_absolute_error: 8.1979 - lr: 1.0000e-04\n",
      "Epoch 21/1000\n",
      "17/17 [==============================] - 3s 180ms/step - loss: 2.4325 - mean_absolute_error: 2.4325 - val_loss: 7.2155 - val_mean_absolute_error: 7.2155 - lr: 1.0000e-04\n",
      "Epoch 22/1000\n",
      "17/17 [==============================] - 3s 180ms/step - loss: 2.3335 - mean_absolute_error: 2.3335 - val_loss: 6.1548 - val_mean_absolute_error: 6.1548 - lr: 1.0000e-04\n",
      "Epoch 23/1000\n",
      "17/17 [==============================] - 3s 180ms/step - loss: 2.2478 - mean_absolute_error: 2.2478 - val_loss: 5.3461 - val_mean_absolute_error: 5.3461 - lr: 1.0000e-04\n",
      "Epoch 24/1000\n",
      "17/17 [==============================] - 3s 180ms/step - loss: 2.1787 - mean_absolute_error: 2.1787 - val_loss: 4.6265 - val_mean_absolute_error: 4.6265 - lr: 1.0000e-04\n",
      "Epoch 25/1000\n",
      "17/17 [==============================] - 3s 179ms/step - loss: 2.1216 - mean_absolute_error: 2.1216 - val_loss: 4.1764 - val_mean_absolute_error: 4.1764 - lr: 1.0000e-04\n",
      "Epoch 26/1000\n",
      "17/17 [==============================] - 3s 180ms/step - loss: 2.0582 - mean_absolute_error: 2.0582 - val_loss: 3.8027 - val_mean_absolute_error: 3.8027 - lr: 1.0000e-04\n",
      "Epoch 27/1000\n",
      "17/17 [==============================] - 3s 179ms/step - loss: 2.0142 - mean_absolute_error: 2.0142 - val_loss: 3.6910 - val_mean_absolute_error: 3.6910 - lr: 1.0000e-04\n",
      "Epoch 28/1000\n",
      "17/17 [==============================] - 3s 179ms/step - loss: 1.9569 - mean_absolute_error: 1.9569 - val_loss: 3.6595 - val_mean_absolute_error: 3.6595 - lr: 1.0000e-04\n",
      "Epoch 29/1000\n",
      "17/17 [==============================] - 3s 180ms/step - loss: 1.9112 - mean_absolute_error: 1.9112 - val_loss: 3.6858 - val_mean_absolute_error: 3.6858 - lr: 1.0000e-04\n",
      "Epoch 30/1000\n",
      "17/17 [==============================] - 3s 179ms/step - loss: 1.8602 - mean_absolute_error: 1.8602 - val_loss: 3.8428 - val_mean_absolute_error: 3.8428 - lr: 1.0000e-04\n",
      "Epoch 31/1000\n",
      "17/17 [==============================] - 3s 179ms/step - loss: 1.8083 - mean_absolute_error: 1.8083 - val_loss: 3.9588 - val_mean_absolute_error: 3.9588 - lr: 1.0000e-04\n",
      "Epoch 32/1000\n",
      "17/17 [==============================] - 3s 179ms/step - loss: 1.7595 - mean_absolute_error: 1.7595 - val_loss: 4.2103 - val_mean_absolute_error: 4.2103 - lr: 1.0000e-04\n",
      "Epoch 33/1000\n",
      "17/17 [==============================] - 3s 180ms/step - loss: 1.7207 - mean_absolute_error: 1.7207 - val_loss: 4.3311 - val_mean_absolute_error: 4.3311 - lr: 1.0000e-04\n",
      "Epoch 34/1000\n",
      "17/17 [==============================] - 3s 180ms/step - loss: 1.6766 - mean_absolute_error: 1.6766 - val_loss: 4.5373 - val_mean_absolute_error: 4.5373 - lr: 1.0000e-04\n",
      "Epoch 35/1000\n",
      "17/17 [==============================] - 3s 180ms/step - loss: 1.6401 - mean_absolute_error: 1.6401 - val_loss: 4.6201 - val_mean_absolute_error: 4.6201 - lr: 1.0000e-04\n",
      "Epoch 36/1000\n",
      "17/17 [==============================] - 3s 180ms/step - loss: 1.5991 - mean_absolute_error: 1.5991 - val_loss: 4.7555 - val_mean_absolute_error: 4.7555 - lr: 1.0000e-04\n",
      "Epoch 37/1000\n",
      "17/17 [==============================] - 3s 180ms/step - loss: 1.5631 - mean_absolute_error: 1.5631 - val_loss: 4.8006 - val_mean_absolute_error: 4.8006 - lr: 1.0000e-04\n",
      "Epoch 38/1000\n",
      "17/17 [==============================] - 3s 180ms/step - loss: 1.5198 - mean_absolute_error: 1.5198 - val_loss: 4.8702 - val_mean_absolute_error: 4.8702 - lr: 1.0000e-04\n",
      "Epoch 39/1000\n",
      "17/17 [==============================] - 3s 180ms/step - loss: 1.4474 - mean_absolute_error: 1.4474 - val_loss: 4.8820 - val_mean_absolute_error: 4.8820 - lr: 1.0000e-05\n",
      "Epoch 40/1000\n",
      "17/17 [==============================] - 3s 181ms/step - loss: 1.4359 - mean_absolute_error: 1.4359 - val_loss: 4.8883 - val_mean_absolute_error: 4.8883 - lr: 1.0000e-05\n",
      "Epoch 41/1000\n",
      "17/17 [==============================] - 3s 180ms/step - loss: 1.4291 - mean_absolute_error: 1.4291 - val_loss: 4.8911 - val_mean_absolute_error: 4.8911 - lr: 1.0000e-05\n",
      "Epoch 42/1000\n",
      "17/17 [==============================] - 3s 180ms/step - loss: 1.4242 - mean_absolute_error: 1.4242 - val_loss: 4.8906 - val_mean_absolute_error: 4.8906 - lr: 1.0000e-05\n",
      "Epoch 43/1000\n",
      "17/17 [==============================] - 3s 180ms/step - loss: 1.4199 - mean_absolute_error: 1.4199 - val_loss: 4.8858 - val_mean_absolute_error: 4.8858 - lr: 1.0000e-05\n",
      "Epoch 44/1000\n",
      "17/17 [==============================] - 3s 180ms/step - loss: 1.4159 - mean_absolute_error: 1.4159 - val_loss: 4.8780 - val_mean_absolute_error: 4.8780 - lr: 1.0000e-05\n",
      "Epoch 45/1000\n",
      "17/17 [==============================] - 3s 180ms/step - loss: 1.4119 - mean_absolute_error: 1.4119 - val_loss: 4.8688 - val_mean_absolute_error: 4.8688 - lr: 1.0000e-05\n",
      "Epoch 46/1000\n",
      "17/17 [==============================] - 3s 180ms/step - loss: 1.4080 - mean_absolute_error: 1.4080 - val_loss: 4.8610 - val_mean_absolute_error: 4.8610 - lr: 1.0000e-05\n",
      "Epoch 47/1000\n",
      "17/17 [==============================] - 3s 180ms/step - loss: 1.4041 - mean_absolute_error: 1.4041 - val_loss: 4.8524 - val_mean_absolute_error: 4.8524 - lr: 1.0000e-05\n",
      "Epoch 48/1000\n",
      "17/17 [==============================] - 3s 180ms/step - loss: 1.4002 - mean_absolute_error: 1.4002 - val_loss: 4.8431 - val_mean_absolute_error: 4.8431 - lr: 1.0000e-05\n",
      "Epoch 49/1000\n",
      "17/17 [==============================] - 3s 180ms/step - loss: 1.3943 - mean_absolute_error: 1.3943 - val_loss: 4.8307 - val_mean_absolute_error: 4.8307 - lr: 1.0000e-06\n",
      "Epoch 50/1000\n",
      "17/17 [==============================] - 3s 180ms/step - loss: 1.3939 - mean_absolute_error: 1.3939 - val_loss: 4.8197 - val_mean_absolute_error: 4.8197 - lr: 1.0000e-06\n",
      "Epoch 51/1000\n",
      "17/17 [==============================] - 3s 180ms/step - loss: 1.3935 - mean_absolute_error: 1.3935 - val_loss: 4.8095 - val_mean_absolute_error: 4.8095 - lr: 1.0000e-06\n",
      "3th K-fold\n",
      "Epoch 1/1000\n",
      "17/17 [==============================] - 14s 208ms/step - loss: 9.4069 - mean_absolute_error: 9.4069 - val_loss: 15.2948 - val_mean_absolute_error: 15.2948 - lr: 0.0010\n",
      "Epoch 2/1000\n",
      "17/17 [==============================] - 3s 181ms/step - loss: 5.0637 - mean_absolute_error: 5.0637 - val_loss: 13.9684 - val_mean_absolute_error: 13.9684 - lr: 0.0010\n",
      "Epoch 3/1000\n",
      "17/17 [==============================] - 3s 182ms/step - loss: 5.3693 - mean_absolute_error: 5.3693 - val_loss: 10.7770 - val_mean_absolute_error: 10.7770 - lr: 0.0010\n",
      "Epoch 4/1000\n",
      "17/17 [==============================] - 3s 181ms/step - loss: 4.9151 - mean_absolute_error: 4.9151 - val_loss: 11.4945 - val_mean_absolute_error: 11.4945 - lr: 0.0010\n",
      "Epoch 5/1000\n",
      "17/17 [==============================] - 3s 180ms/step - loss: 4.2857 - mean_absolute_error: 4.2857 - val_loss: 9.8458 - val_mean_absolute_error: 9.8458 - lr: 0.0010\n",
      "Epoch 6/1000\n",
      "17/17 [==============================] - 3s 181ms/step - loss: 4.6549 - mean_absolute_error: 4.6549 - val_loss: 5.6055 - val_mean_absolute_error: 5.6055 - lr: 0.0010\n",
      "Epoch 7/1000\n",
      "17/17 [==============================] - 3s 181ms/step - loss: 4.0091 - mean_absolute_error: 4.0091 - val_loss: 11.5892 - val_mean_absolute_error: 11.5892 - lr: 0.0010\n",
      "Epoch 8/1000\n",
      "17/17 [==============================] - 3s 181ms/step - loss: 3.8510 - mean_absolute_error: 3.8510 - val_loss: 9.4448 - val_mean_absolute_error: 9.4448 - lr: 0.0010\n",
      "Epoch 9/1000\n",
      "17/17 [==============================] - 3s 182ms/step - loss: 3.6101 - mean_absolute_error: 3.6101 - val_loss: 10.1640 - val_mean_absolute_error: 10.1640 - lr: 0.0010\n",
      "Epoch 10/1000\n",
      "17/17 [==============================] - 3s 181ms/step - loss: 3.5245 - mean_absolute_error: 3.5245 - val_loss: 6.7303 - val_mean_absolute_error: 6.7303 - lr: 0.0010\n",
      "Epoch 11/1000\n",
      "17/17 [==============================] - 3s 181ms/step - loss: 3.6619 - mean_absolute_error: 3.6619 - val_loss: 6.6806 - val_mean_absolute_error: 6.6806 - lr: 0.0010\n",
      "Epoch 12/1000\n",
      "17/17 [==============================] - 3s 181ms/step - loss: 3.1773 - mean_absolute_error: 3.1773 - val_loss: 9.9881 - val_mean_absolute_error: 9.9881 - lr: 0.0010\n",
      "Epoch 13/1000\n",
      "17/17 [==============================] - 3s 181ms/step - loss: 3.1685 - mean_absolute_error: 3.1685 - val_loss: 12.2676 - val_mean_absolute_error: 12.2676 - lr: 0.0010\n",
      "Epoch 14/1000\n",
      "17/17 [==============================] - 3s 181ms/step - loss: 2.8182 - mean_absolute_error: 2.8182 - val_loss: 8.0605 - val_mean_absolute_error: 8.0605 - lr: 0.0010\n",
      "Epoch 15/1000\n",
      "17/17 [==============================] - 3s 181ms/step - loss: 2.7707 - mean_absolute_error: 2.7707 - val_loss: 12.2121 - val_mean_absolute_error: 12.2121 - lr: 0.0010\n",
      "Epoch 16/1000\n",
      "17/17 [==============================] - 3s 181ms/step - loss: 2.8190 - mean_absolute_error: 2.8190 - val_loss: 4.3832 - val_mean_absolute_error: 4.3832 - lr: 0.0010\n",
      "Epoch 17/1000\n",
      "17/17 [==============================] - 3s 181ms/step - loss: 2.3445 - mean_absolute_error: 2.3445 - val_loss: 8.2849 - val_mean_absolute_error: 8.2849 - lr: 0.0010\n",
      "Epoch 18/1000\n",
      "17/17 [==============================] - 3s 181ms/step - loss: 2.3728 - mean_absolute_error: 2.3728 - val_loss: 6.0614 - val_mean_absolute_error: 6.0614 - lr: 0.0010\n",
      "Epoch 19/1000\n",
      "17/17 [==============================] - 3s 181ms/step - loss: 2.2884 - mean_absolute_error: 2.2884 - val_loss: 7.4665 - val_mean_absolute_error: 7.4665 - lr: 0.0010\n",
      "Epoch 20/1000\n",
      "17/17 [==============================] - 3s 182ms/step - loss: 2.8276 - mean_absolute_error: 2.8276 - val_loss: 5.2965 - val_mean_absolute_error: 5.2965 - lr: 0.0010\n",
      "Epoch 21/1000\n",
      "17/17 [==============================] - 3s 181ms/step - loss: 2.1542 - mean_absolute_error: 2.1542 - val_loss: 6.0351 - val_mean_absolute_error: 6.0351 - lr: 0.0010\n",
      "Epoch 22/1000\n",
      "17/17 [==============================] - 3s 181ms/step - loss: 2.2841 - mean_absolute_error: 2.2841 - val_loss: 5.1838 - val_mean_absolute_error: 5.1838 - lr: 0.0010\n",
      "Epoch 23/1000\n",
      "17/17 [==============================] - 3s 181ms/step - loss: 2.5102 - mean_absolute_error: 2.5102 - val_loss: 5.3587 - val_mean_absolute_error: 5.3587 - lr: 0.0010\n",
      "Epoch 24/1000\n",
      "17/17 [==============================] - 3s 181ms/step - loss: 2.4172 - mean_absolute_error: 2.4172 - val_loss: 4.8936 - val_mean_absolute_error: 4.8936 - lr: 0.0010\n",
      "Epoch 25/1000\n",
      "17/17 [==============================] - 3s 181ms/step - loss: 2.0254 - mean_absolute_error: 2.0254 - val_loss: 4.6516 - val_mean_absolute_error: 4.6516 - lr: 0.0010\n",
      "Epoch 26/1000\n",
      "17/17 [==============================] - 3s 181ms/step - loss: 2.4230 - mean_absolute_error: 2.4230 - val_loss: 5.1053 - val_mean_absolute_error: 5.1053 - lr: 0.0010\n",
      "Epoch 27/1000\n",
      "17/17 [==============================] - 3s 181ms/step - loss: 2.1767 - mean_absolute_error: 2.1767 - val_loss: 4.6485 - val_mean_absolute_error: 4.6485 - lr: 1.0000e-04\n",
      "Epoch 28/1000\n",
      "17/17 [==============================] - 3s 182ms/step - loss: 1.7483 - mean_absolute_error: 1.7483 - val_loss: 4.2407 - val_mean_absolute_error: 4.2407 - lr: 1.0000e-04\n",
      "Epoch 29/1000\n",
      "17/17 [==============================] - 3s 182ms/step - loss: 1.6041 - mean_absolute_error: 1.6041 - val_loss: 3.8498 - val_mean_absolute_error: 3.8498 - lr: 1.0000e-04\n",
      "Epoch 30/1000\n",
      "17/17 [==============================] - 3s 182ms/step - loss: 1.4873 - mean_absolute_error: 1.4873 - val_loss: 3.5566 - val_mean_absolute_error: 3.5566 - lr: 1.0000e-04\n",
      "Epoch 31/1000\n",
      "17/17 [==============================] - 3s 182ms/step - loss: 1.3815 - mean_absolute_error: 1.3815 - val_loss: 3.2853 - val_mean_absolute_error: 3.2853 - lr: 1.0000e-04\n",
      "Epoch 32/1000\n",
      "17/17 [==============================] - 3s 182ms/step - loss: 1.3273 - mean_absolute_error: 1.3273 - val_loss: 3.1052 - val_mean_absolute_error: 3.1052 - lr: 1.0000e-04\n",
      "Epoch 33/1000\n",
      "17/17 [==============================] - 3s 181ms/step - loss: 1.2801 - mean_absolute_error: 1.2801 - val_loss: 2.9878 - val_mean_absolute_error: 2.9878 - lr: 1.0000e-04\n",
      "Epoch 34/1000\n",
      "17/17 [==============================] - 3s 182ms/step - loss: 1.2301 - mean_absolute_error: 1.2301 - val_loss: 2.9295 - val_mean_absolute_error: 2.9295 - lr: 1.0000e-04\n",
      "Epoch 35/1000\n",
      "17/17 [==============================] - 3s 182ms/step - loss: 1.1839 - mean_absolute_error: 1.1839 - val_loss: 2.9035 - val_mean_absolute_error: 2.9035 - lr: 1.0000e-04\n",
      "Epoch 36/1000\n",
      "17/17 [==============================] - 3s 182ms/step - loss: 1.1577 - mean_absolute_error: 1.1577 - val_loss: 2.9148 - val_mean_absolute_error: 2.9148 - lr: 1.0000e-04\n",
      "Epoch 37/1000\n",
      "17/17 [==============================] - 3s 182ms/step - loss: 1.1217 - mean_absolute_error: 1.1217 - val_loss: 2.9590 - val_mean_absolute_error: 2.9590 - lr: 1.0000e-04\n",
      "Epoch 38/1000\n",
      "17/17 [==============================] - 3s 182ms/step - loss: 1.0750 - mean_absolute_error: 1.0750 - val_loss: 3.0158 - val_mean_absolute_error: 3.0158 - lr: 1.0000e-04\n",
      "Epoch 39/1000\n",
      "17/17 [==============================] - 3s 182ms/step - loss: 1.0372 - mean_absolute_error: 1.0372 - val_loss: 3.0654 - val_mean_absolute_error: 3.0654 - lr: 1.0000e-04\n",
      "Epoch 40/1000\n",
      "17/17 [==============================] - 3s 181ms/step - loss: 1.0174 - mean_absolute_error: 1.0174 - val_loss: 3.1134 - val_mean_absolute_error: 3.1134 - lr: 1.0000e-04\n",
      "Epoch 41/1000\n",
      "17/17 [==============================] - 3s 181ms/step - loss: 0.9989 - mean_absolute_error: 0.9989 - val_loss: 3.1469 - val_mean_absolute_error: 3.1469 - lr: 1.0000e-04\n",
      "Epoch 42/1000\n",
      "17/17 [==============================] - 3s 181ms/step - loss: 0.9716 - mean_absolute_error: 0.9716 - val_loss: 3.1954 - val_mean_absolute_error: 3.1954 - lr: 1.0000e-04\n",
      "Epoch 43/1000\n",
      "17/17 [==============================] - 3s 181ms/step - loss: 0.9314 - mean_absolute_error: 0.9314 - val_loss: 3.2462 - val_mean_absolute_error: 3.2462 - lr: 1.0000e-04\n",
      "Epoch 44/1000\n",
      "17/17 [==============================] - 3s 181ms/step - loss: 0.9061 - mean_absolute_error: 0.9061 - val_loss: 3.2939 - val_mean_absolute_error: 3.2939 - lr: 1.0000e-04\n",
      "Epoch 45/1000\n",
      "17/17 [==============================] - 3s 181ms/step - loss: 0.8911 - mean_absolute_error: 0.8911 - val_loss: 3.3293 - val_mean_absolute_error: 3.3293 - lr: 1.0000e-04\n",
      "Epoch 46/1000\n",
      "17/17 [==============================] - 3s 182ms/step - loss: 0.8848 - mean_absolute_error: 0.8848 - val_loss: 3.3448 - val_mean_absolute_error: 3.3448 - lr: 1.0000e-05\n",
      "Epoch 47/1000\n",
      "17/17 [==============================] - 3s 181ms/step - loss: 0.8634 - mean_absolute_error: 0.8634 - val_loss: 3.3625 - val_mean_absolute_error: 3.3625 - lr: 1.0000e-05\n",
      "Epoch 48/1000\n",
      "17/17 [==============================] - 3s 182ms/step - loss: 0.8581 - mean_absolute_error: 0.8581 - val_loss: 3.3826 - val_mean_absolute_error: 3.3826 - lr: 1.0000e-05\n",
      "Epoch 49/1000\n",
      "17/17 [==============================] - 3s 182ms/step - loss: 0.8562 - mean_absolute_error: 0.8562 - val_loss: 3.3976 - val_mean_absolute_error: 3.3976 - lr: 1.0000e-05\n",
      "Epoch 50/1000\n",
      "17/17 [==============================] - 3s 181ms/step - loss: 0.8542 - mean_absolute_error: 0.8542 - val_loss: 3.4106 - val_mean_absolute_error: 3.4106 - lr: 1.0000e-05\n",
      "Epoch 51/1000\n",
      "17/17 [==============================] - 3s 182ms/step - loss: 0.8518 - mean_absolute_error: 0.8518 - val_loss: 3.4227 - val_mean_absolute_error: 3.4227 - lr: 1.0000e-05\n",
      "Epoch 52/1000\n",
      "17/17 [==============================] - 3s 182ms/step - loss: 0.8496 - mean_absolute_error: 0.8496 - val_loss: 3.4333 - val_mean_absolute_error: 3.4333 - lr: 1.0000e-05\n",
      "Epoch 53/1000\n",
      "17/17 [==============================] - 3s 182ms/step - loss: 0.8475 - mean_absolute_error: 0.8475 - val_loss: 3.4417 - val_mean_absolute_error: 3.4417 - lr: 1.0000e-05\n",
      "Epoch 54/1000\n",
      "17/17 [==============================] - 3s 182ms/step - loss: 0.8454 - mean_absolute_error: 0.8454 - val_loss: 3.4494 - val_mean_absolute_error: 3.4494 - lr: 1.0000e-05\n",
      "Epoch 55/1000\n",
      "17/17 [==============================] - 3s 181ms/step - loss: 0.8432 - mean_absolute_error: 0.8432 - val_loss: 3.4562 - val_mean_absolute_error: 3.4562 - lr: 1.0000e-05\n",
      "Epoch 56/1000\n",
      "17/17 [==============================] - 3s 181ms/step - loss: 0.8407 - mean_absolute_error: 0.8407 - val_loss: 3.4630 - val_mean_absolute_error: 3.4630 - lr: 1.0000e-06\n",
      "Epoch 57/1000\n",
      "17/17 [==============================] - 3s 182ms/step - loss: 0.8405 - mean_absolute_error: 0.8405 - val_loss: 3.4687 - val_mean_absolute_error: 3.4687 - lr: 1.0000e-06\n",
      "Epoch 58/1000\n",
      "17/17 [==============================] - 3s 182ms/step - loss: 0.8402 - mean_absolute_error: 0.8402 - val_loss: 3.4737 - val_mean_absolute_error: 3.4737 - lr: 1.0000e-06\n",
      "4th K-fold\n",
      "Epoch 1/1000\n",
      "17/17 [==============================] - 15s 209ms/step - loss: 8.0909 - mean_absolute_error: 8.0909 - val_loss: 15.1994 - val_mean_absolute_error: 15.1994 - lr: 0.0010\n",
      "Epoch 2/1000\n",
      "17/17 [==============================] - 3s 180ms/step - loss: 5.3094 - mean_absolute_error: 5.3094 - val_loss: 16.7870 - val_mean_absolute_error: 16.7870 - lr: 0.0010\n",
      "Epoch 3/1000\n",
      "17/17 [==============================] - 3s 180ms/step - loss: 5.5226 - mean_absolute_error: 5.5226 - val_loss: 14.6087 - val_mean_absolute_error: 14.6087 - lr: 0.0010\n",
      "Epoch 4/1000\n",
      "17/17 [==============================] - 3s 180ms/step - loss: 4.4661 - mean_absolute_error: 4.4661 - val_loss: 14.9668 - val_mean_absolute_error: 14.9668 - lr: 0.0010\n",
      "Epoch 5/1000\n",
      "17/17 [==============================] - 3s 180ms/step - loss: 4.7866 - mean_absolute_error: 4.7866 - val_loss: 8.0172 - val_mean_absolute_error: 8.0172 - lr: 0.0010\n",
      "Epoch 6/1000\n",
      "17/17 [==============================] - 3s 180ms/step - loss: 3.6878 - mean_absolute_error: 3.6878 - val_loss: 12.0741 - val_mean_absolute_error: 12.0741 - lr: 0.0010\n",
      "Epoch 7/1000\n",
      "17/17 [==============================] - 3s 181ms/step - loss: 3.4137 - mean_absolute_error: 3.4137 - val_loss: 10.4311 - val_mean_absolute_error: 10.4311 - lr: 0.0010\n",
      "Epoch 8/1000\n",
      "17/17 [==============================] - 3s 181ms/step - loss: 3.6055 - mean_absolute_error: 3.6055 - val_loss: 10.6551 - val_mean_absolute_error: 10.6551 - lr: 0.0010\n",
      "Epoch 9/1000\n",
      "17/17 [==============================] - 3s 180ms/step - loss: 4.0325 - mean_absolute_error: 4.0325 - val_loss: 11.4755 - val_mean_absolute_error: 11.4755 - lr: 0.0010\n",
      "Epoch 10/1000\n",
      "17/17 [==============================] - 3s 180ms/step - loss: 3.2783 - mean_absolute_error: 3.2783 - val_loss: 11.6679 - val_mean_absolute_error: 11.6679 - lr: 0.0010\n",
      "Epoch 11/1000\n",
      "17/17 [==============================] - 3s 180ms/step - loss: 4.0230 - mean_absolute_error: 4.0230 - val_loss: 7.5532 - val_mean_absolute_error: 7.5532 - lr: 0.0010\n",
      "Epoch 12/1000\n",
      "17/17 [==============================] - 3s 180ms/step - loss: 3.0992 - mean_absolute_error: 3.0992 - val_loss: 8.8119 - val_mean_absolute_error: 8.8119 - lr: 0.0010\n",
      "Epoch 13/1000\n",
      "17/17 [==============================] - 3s 180ms/step - loss: 2.9478 - mean_absolute_error: 2.9478 - val_loss: 11.2223 - val_mean_absolute_error: 11.2223 - lr: 0.0010\n",
      "Epoch 14/1000\n",
      "17/17 [==============================] - 3s 180ms/step - loss: 3.0361 - mean_absolute_error: 3.0361 - val_loss: 7.3842 - val_mean_absolute_error: 7.3842 - lr: 0.0010\n",
      "Epoch 15/1000\n",
      "17/17 [==============================] - 3s 181ms/step - loss: 3.8578 - mean_absolute_error: 3.8578 - val_loss: 8.9991 - val_mean_absolute_error: 8.9991 - lr: 0.0010\n",
      "Epoch 16/1000\n",
      "17/17 [==============================] - 3s 180ms/step - loss: 4.4802 - mean_absolute_error: 4.4802 - val_loss: 8.7105 - val_mean_absolute_error: 8.7105 - lr: 0.0010\n",
      "Epoch 17/1000\n",
      "17/17 [==============================] - 3s 180ms/step - loss: 5.1826 - mean_absolute_error: 5.1826 - val_loss: 5.5342 - val_mean_absolute_error: 5.5342 - lr: 0.0010\n",
      "Epoch 18/1000\n",
      "17/17 [==============================] - 3s 181ms/step - loss: 3.5188 - mean_absolute_error: 3.5188 - val_loss: 6.5228 - val_mean_absolute_error: 6.5228 - lr: 0.0010\n",
      "Epoch 19/1000\n",
      "17/17 [==============================] - 3s 180ms/step - loss: 3.4733 - mean_absolute_error: 3.4733 - val_loss: 6.4584 - val_mean_absolute_error: 6.4584 - lr: 0.0010\n",
      "Epoch 20/1000\n",
      "17/17 [==============================] - 3s 180ms/step - loss: 4.6183 - mean_absolute_error: 4.6183 - val_loss: 5.4375 - val_mean_absolute_error: 5.4375 - lr: 0.0010\n",
      "Epoch 21/1000\n",
      "17/17 [==============================] - 3s 180ms/step - loss: 3.5655 - mean_absolute_error: 3.5655 - val_loss: 4.3788 - val_mean_absolute_error: 4.3788 - lr: 0.0010\n",
      "Epoch 22/1000\n",
      "17/17 [==============================] - 3s 180ms/step - loss: 2.7286 - mean_absolute_error: 2.7286 - val_loss: 5.9278 - val_mean_absolute_error: 5.9278 - lr: 0.0010\n",
      "Epoch 23/1000\n",
      "17/17 [==============================] - 3s 181ms/step - loss: 2.5045 - mean_absolute_error: 2.5045 - val_loss: 5.6440 - val_mean_absolute_error: 5.6440 - lr: 0.0010\n",
      "Epoch 24/1000\n",
      "17/17 [==============================] - 3s 181ms/step - loss: 2.6110 - mean_absolute_error: 2.6110 - val_loss: 6.5005 - val_mean_absolute_error: 6.5005 - lr: 0.0010\n",
      "Epoch 25/1000\n",
      "17/17 [==============================] - 3s 180ms/step - loss: 2.8803 - mean_absolute_error: 2.8803 - val_loss: 5.4871 - val_mean_absolute_error: 5.4871 - lr: 0.0010\n",
      "Epoch 26/1000\n",
      "17/17 [==============================] - 3s 182ms/step - loss: 2.7373 - mean_absolute_error: 2.7373 - val_loss: 5.7549 - val_mean_absolute_error: 5.7549 - lr: 0.0010\n",
      "Epoch 27/1000\n",
      "17/17 [==============================] - 3s 180ms/step - loss: 3.0795 - mean_absolute_error: 3.0795 - val_loss: 6.4406 - val_mean_absolute_error: 6.4406 - lr: 0.0010\n",
      "Epoch 28/1000\n",
      "17/17 [==============================] - 3s 180ms/step - loss: 2.8246 - mean_absolute_error: 2.8246 - val_loss: 5.1044 - val_mean_absolute_error: 5.1044 - lr: 0.0010\n",
      "Epoch 29/1000\n",
      "17/17 [==============================] - 3s 180ms/step - loss: 4.0160 - mean_absolute_error: 4.0160 - val_loss: 5.1789 - val_mean_absolute_error: 5.1789 - lr: 0.0010\n",
      "Epoch 30/1000\n",
      "17/17 [==============================] - 3s 180ms/step - loss: 3.2273 - mean_absolute_error: 3.2273 - val_loss: 5.7528 - val_mean_absolute_error: 5.7528 - lr: 0.0010\n",
      "Epoch 31/1000\n",
      "17/17 [==============================] - 3s 181ms/step - loss: 2.8014 - mean_absolute_error: 2.8014 - val_loss: 5.3340 - val_mean_absolute_error: 5.3340 - lr: 0.0010\n",
      "Epoch 32/1000\n",
      "17/17 [==============================] - 3s 181ms/step - loss: 3.1261 - mean_absolute_error: 3.1261 - val_loss: 4.8992 - val_mean_absolute_error: 4.8992 - lr: 1.0000e-04\n",
      "Epoch 33/1000\n",
      "17/17 [==============================] - 3s 181ms/step - loss: 2.2566 - mean_absolute_error: 2.2566 - val_loss: 5.4179 - val_mean_absolute_error: 5.4179 - lr: 1.0000e-04\n",
      "Epoch 34/1000\n",
      "17/17 [==============================] - 3s 181ms/step - loss: 1.9962 - mean_absolute_error: 1.9962 - val_loss: 5.5080 - val_mean_absolute_error: 5.5080 - lr: 1.0000e-04\n",
      "Epoch 35/1000\n",
      "17/17 [==============================] - 3s 181ms/step - loss: 1.9022 - mean_absolute_error: 1.9022 - val_loss: 5.2613 - val_mean_absolute_error: 5.2613 - lr: 1.0000e-04\n",
      "Epoch 36/1000\n",
      "17/17 [==============================] - 3s 180ms/step - loss: 1.8316 - mean_absolute_error: 1.8316 - val_loss: 5.2314 - val_mean_absolute_error: 5.2314 - lr: 1.0000e-04\n",
      "Epoch 37/1000\n",
      "17/17 [==============================] - 3s 182ms/step - loss: 1.7747 - mean_absolute_error: 1.7747 - val_loss: 5.2157 - val_mean_absolute_error: 5.2157 - lr: 1.0000e-04\n",
      "Epoch 38/1000\n",
      "17/17 [==============================] - 3s 180ms/step - loss: 1.7256 - mean_absolute_error: 1.7256 - val_loss: 5.1441 - val_mean_absolute_error: 5.1441 - lr: 1.0000e-04\n",
      "Epoch 39/1000\n",
      "17/17 [==============================] - 3s 181ms/step - loss: 1.6814 - mean_absolute_error: 1.6814 - val_loss: 5.1034 - val_mean_absolute_error: 5.1034 - lr: 1.0000e-04\n",
      "Epoch 40/1000\n",
      "17/17 [==============================] - 3s 181ms/step - loss: 1.6388 - mean_absolute_error: 1.6388 - val_loss: 5.0817 - val_mean_absolute_error: 5.0817 - lr: 1.0000e-04\n",
      "Epoch 41/1000\n",
      "17/17 [==============================] - 3s 182ms/step - loss: 1.5978 - mean_absolute_error: 1.5978 - val_loss: 5.0649 - val_mean_absolute_error: 5.0649 - lr: 1.0000e-04\n",
      "Epoch 42/1000\n",
      "17/17 [==============================] - 3s 181ms/step - loss: 1.5414 - mean_absolute_error: 1.5414 - val_loss: 5.0422 - val_mean_absolute_error: 5.0422 - lr: 1.0000e-05\n",
      "Epoch 43/1000\n",
      "17/17 [==============================] - 3s 181ms/step - loss: 1.5378 - mean_absolute_error: 1.5378 - val_loss: 5.0217 - val_mean_absolute_error: 5.0217 - lr: 1.0000e-05\n",
      "Epoch 44/1000\n",
      "17/17 [==============================] - 3s 180ms/step - loss: 1.5341 - mean_absolute_error: 1.5341 - val_loss: 5.0032 - val_mean_absolute_error: 5.0032 - lr: 1.0000e-05\n",
      "5th K-fold\n",
      "Epoch 1/1000\n",
      "17/17 [==============================] - 14s 214ms/step - loss: 9.5907 - mean_absolute_error: 9.5907 - val_loss: 14.1240 - val_mean_absolute_error: 14.1240 - lr: 0.0010\n",
      "Epoch 2/1000\n",
      "17/17 [==============================] - 3s 182ms/step - loss: 5.7909 - mean_absolute_error: 5.7909 - val_loss: 12.3435 - val_mean_absolute_error: 12.3435 - lr: 0.0010\n",
      "Epoch 3/1000\n",
      "17/17 [==============================] - 3s 181ms/step - loss: 5.6452 - mean_absolute_error: 5.6452 - val_loss: 7.4374 - val_mean_absolute_error: 7.4374 - lr: 0.0010\n",
      "Epoch 4/1000\n",
      "17/17 [==============================] - 3s 182ms/step - loss: 4.6177 - mean_absolute_error: 4.6177 - val_loss: 5.7360 - val_mean_absolute_error: 5.7360 - lr: 0.0010\n",
      "Epoch 5/1000\n",
      "17/17 [==============================] - 3s 182ms/step - loss: 4.4583 - mean_absolute_error: 4.4583 - val_loss: 3.6870 - val_mean_absolute_error: 3.6870 - lr: 0.0010\n",
      "Epoch 6/1000\n",
      "17/17 [==============================] - 3s 181ms/step - loss: 4.6126 - mean_absolute_error: 4.6126 - val_loss: 3.6545 - val_mean_absolute_error: 3.6545 - lr: 0.0010\n",
      "Epoch 7/1000\n",
      "17/17 [==============================] - 3s 181ms/step - loss: 4.3733 - mean_absolute_error: 4.3733 - val_loss: 3.5278 - val_mean_absolute_error: 3.5278 - lr: 0.0010\n",
      "Epoch 8/1000\n",
      "17/17 [==============================] - 3s 181ms/step - loss: 4.1110 - mean_absolute_error: 4.1110 - val_loss: 4.4451 - val_mean_absolute_error: 4.4451 - lr: 0.0010\n",
      "Epoch 9/1000\n",
      "17/17 [==============================] - 3s 182ms/step - loss: 4.2470 - mean_absolute_error: 4.2470 - val_loss: 3.4412 - val_mean_absolute_error: 3.4412 - lr: 0.0010\n",
      "Epoch 10/1000\n",
      "17/17 [==============================] - 3s 181ms/step - loss: 4.1051 - mean_absolute_error: 4.1051 - val_loss: 3.4520 - val_mean_absolute_error: 3.4520 - lr: 0.0010\n",
      "Epoch 11/1000\n",
      "17/17 [==============================] - 3s 181ms/step - loss: 4.3516 - mean_absolute_error: 4.3516 - val_loss: 3.6075 - val_mean_absolute_error: 3.6075 - lr: 0.0010\n",
      "Epoch 12/1000\n",
      "17/17 [==============================] - 3s 182ms/step - loss: 4.1888 - mean_absolute_error: 4.1888 - val_loss: 5.9835 - val_mean_absolute_error: 5.9835 - lr: 0.0010\n",
      "Epoch 13/1000\n",
      "17/17 [==============================] - 3s 182ms/step - loss: 4.8365 - mean_absolute_error: 4.8365 - val_loss: 5.7585 - val_mean_absolute_error: 5.7585 - lr: 0.0010\n",
      "Epoch 14/1000\n",
      "17/17 [==============================] - 3s 181ms/step - loss: 4.3763 - mean_absolute_error: 4.3763 - val_loss: 3.7872 - val_mean_absolute_error: 3.7872 - lr: 0.0010\n",
      "Epoch 15/1000\n",
      "17/17 [==============================] - 3s 182ms/step - loss: 4.1470 - mean_absolute_error: 4.1470 - val_loss: 4.2976 - val_mean_absolute_error: 4.2976 - lr: 0.0010\n",
      "Epoch 16/1000\n",
      "17/17 [==============================] - 3s 181ms/step - loss: 3.8804 - mean_absolute_error: 3.8804 - val_loss: 4.8398 - val_mean_absolute_error: 4.8398 - lr: 0.0010\n",
      "Epoch 17/1000\n",
      "17/17 [==============================] - 3s 182ms/step - loss: 3.6048 - mean_absolute_error: 3.6048 - val_loss: 5.1843 - val_mean_absolute_error: 5.1843 - lr: 0.0010\n",
      "Epoch 18/1000\n",
      "17/17 [==============================] - 3s 181ms/step - loss: 3.4919 - mean_absolute_error: 3.4919 - val_loss: 3.8823 - val_mean_absolute_error: 3.8823 - lr: 0.0010\n",
      "Epoch 19/1000\n",
      "17/17 [==============================] - 3s 181ms/step - loss: 3.4602 - mean_absolute_error: 3.4602 - val_loss: 5.6025 - val_mean_absolute_error: 5.6025 - lr: 0.0010\n",
      "Epoch 20/1000\n",
      "17/17 [==============================] - 3s 181ms/step - loss: 2.8056 - mean_absolute_error: 2.8056 - val_loss: 4.2268 - val_mean_absolute_error: 4.2268 - lr: 1.0000e-04\n",
      "Epoch 21/1000\n",
      "17/17 [==============================] - 3s 182ms/step - loss: 2.5163 - mean_absolute_error: 2.5163 - val_loss: 3.8178 - val_mean_absolute_error: 3.8178 - lr: 1.0000e-04\n",
      "Epoch 22/1000\n",
      "17/17 [==============================] - 3s 182ms/step - loss: 2.3517 - mean_absolute_error: 2.3517 - val_loss: 3.4678 - val_mean_absolute_error: 3.4678 - lr: 1.0000e-04\n",
      "Epoch 23/1000\n",
      "17/17 [==============================] - 3s 182ms/step - loss: 2.2584 - mean_absolute_error: 2.2584 - val_loss: 3.3176 - val_mean_absolute_error: 3.3176 - lr: 1.0000e-04\n",
      "Epoch 24/1000\n",
      "17/17 [==============================] - 3s 182ms/step - loss: 2.1876 - mean_absolute_error: 2.1876 - val_loss: 3.2864 - val_mean_absolute_error: 3.2864 - lr: 1.0000e-04\n",
      "Epoch 25/1000\n",
      "17/17 [==============================] - 3s 182ms/step - loss: 2.1251 - mean_absolute_error: 2.1251 - val_loss: 3.2007 - val_mean_absolute_error: 3.2007 - lr: 1.0000e-04\n",
      "Epoch 26/1000\n",
      "17/17 [==============================] - 3s 182ms/step - loss: 2.0690 - mean_absolute_error: 2.0690 - val_loss: 3.1498 - val_mean_absolute_error: 3.1498 - lr: 1.0000e-04\n",
      "Epoch 27/1000\n",
      "17/17 [==============================] - 3s 182ms/step - loss: 2.0096 - mean_absolute_error: 2.0096 - val_loss: 3.1317 - val_mean_absolute_error: 3.1317 - lr: 1.0000e-04\n",
      "Epoch 28/1000\n",
      "17/17 [==============================] - 3s 182ms/step - loss: 1.9560 - mean_absolute_error: 1.9560 - val_loss: 3.2089 - val_mean_absolute_error: 3.2089 - lr: 1.0000e-04\n",
      "Epoch 29/1000\n",
      "17/17 [==============================] - 3s 182ms/step - loss: 1.9070 - mean_absolute_error: 1.9070 - val_loss: 3.2708 - val_mean_absolute_error: 3.2708 - lr: 1.0000e-04\n",
      "Epoch 30/1000\n",
      "17/17 [==============================] - 3s 182ms/step - loss: 1.8585 - mean_absolute_error: 1.8585 - val_loss: 3.4503 - val_mean_absolute_error: 3.4503 - lr: 1.0000e-04\n",
      "Epoch 31/1000\n",
      "17/17 [==============================] - 3s 182ms/step - loss: 1.8225 - mean_absolute_error: 1.8225 - val_loss: 3.4866 - val_mean_absolute_error: 3.4866 - lr: 1.0000e-04\n",
      "Epoch 32/1000\n",
      "17/17 [==============================] - 3s 182ms/step - loss: 1.8022 - mean_absolute_error: 1.8022 - val_loss: 3.8186 - val_mean_absolute_error: 3.8186 - lr: 1.0000e-04\n",
      "Epoch 33/1000\n",
      "17/17 [==============================] - 3s 182ms/step - loss: 1.8467 - mean_absolute_error: 1.8467 - val_loss: 3.7567 - val_mean_absolute_error: 3.7567 - lr: 1.0000e-04\n",
      "Epoch 34/1000\n",
      "17/17 [==============================] - 3s 182ms/step - loss: 1.7724 - mean_absolute_error: 1.7724 - val_loss: 3.9998 - val_mean_absolute_error: 3.9998 - lr: 1.0000e-04\n",
      "Epoch 35/1000\n",
      "17/17 [==============================] - 3s 182ms/step - loss: 1.8127 - mean_absolute_error: 1.8127 - val_loss: 4.1028 - val_mean_absolute_error: 4.1028 - lr: 1.0000e-04\n",
      "Epoch 36/1000\n",
      "17/17 [==============================] - 3s 182ms/step - loss: 1.7005 - mean_absolute_error: 1.7005 - val_loss: 4.0792 - val_mean_absolute_error: 4.0792 - lr: 1.0000e-04\n",
      "Epoch 37/1000\n",
      "17/17 [==============================] - 3s 182ms/step - loss: 1.7692 - mean_absolute_error: 1.7692 - val_loss: 4.3278 - val_mean_absolute_error: 4.3278 - lr: 1.0000e-04\n",
      "Epoch 38/1000\n",
      "17/17 [==============================] - 3s 182ms/step - loss: 1.7118 - mean_absolute_error: 1.7118 - val_loss: 4.2731 - val_mean_absolute_error: 4.2731 - lr: 1.0000e-05\n",
      "Epoch 39/1000\n",
      "17/17 [==============================] - 3s 182ms/step - loss: 1.6284 - mean_absolute_error: 1.6284 - val_loss: 4.2262 - val_mean_absolute_error: 4.2262 - lr: 1.0000e-05\n",
      "Epoch 40/1000\n",
      "17/17 [==============================] - 3s 182ms/step - loss: 1.5660 - mean_absolute_error: 1.5660 - val_loss: 4.1803 - val_mean_absolute_error: 4.1803 - lr: 1.0000e-05\n",
      "Epoch 41/1000\n",
      "17/17 [==============================] - 3s 182ms/step - loss: 1.5447 - mean_absolute_error: 1.5447 - val_loss: 4.1522 - val_mean_absolute_error: 4.1522 - lr: 1.0000e-05\n",
      "Epoch 42/1000\n",
      "17/17 [==============================] - 3s 182ms/step - loss: 1.5390 - mean_absolute_error: 1.5390 - val_loss: 4.1415 - val_mean_absolute_error: 4.1415 - lr: 1.0000e-05\n",
      "Epoch 43/1000\n",
      "17/17 [==============================] - 3s 183ms/step - loss: 1.5342 - mean_absolute_error: 1.5342 - val_loss: 4.1382 - val_mean_absolute_error: 4.1382 - lr: 1.0000e-05\n",
      "Epoch 44/1000\n",
      "17/17 [==============================] - 3s 182ms/step - loss: 1.5297 - mean_absolute_error: 1.5297 - val_loss: 4.1345 - val_mean_absolute_error: 4.1345 - lr: 1.0000e-05\n",
      "Epoch 45/1000\n",
      "17/17 [==============================] - 3s 182ms/step - loss: 1.5253 - mean_absolute_error: 1.5253 - val_loss: 4.1291 - val_mean_absolute_error: 4.1291 - lr: 1.0000e-05\n",
      "Epoch 46/1000\n",
      "17/17 [==============================] - 3s 182ms/step - loss: 1.5211 - mean_absolute_error: 1.5211 - val_loss: 4.1235 - val_mean_absolute_error: 4.1235 - lr: 1.0000e-05\n",
      "Epoch 47/1000\n",
      "17/17 [==============================] - 3s 182ms/step - loss: 1.5170 - mean_absolute_error: 1.5170 - val_loss: 4.1201 - val_mean_absolute_error: 4.1201 - lr: 1.0000e-05\n",
      "Epoch 48/1000\n",
      "17/17 [==============================] - 3s 182ms/step - loss: 1.5116 - mean_absolute_error: 1.5116 - val_loss: 4.1146 - val_mean_absolute_error: 4.1146 - lr: 1.0000e-06\n",
      "Epoch 49/1000\n",
      "17/17 [==============================] - 3s 182ms/step - loss: 1.5112 - mean_absolute_error: 1.5112 - val_loss: 4.1097 - val_mean_absolute_error: 4.1097 - lr: 1.0000e-06\n",
      "Epoch 50/1000\n",
      "17/17 [==============================] - 3s 182ms/step - loss: 1.5107 - mean_absolute_error: 1.5107 - val_loss: 4.1055 - val_mean_absolute_error: 4.1055 - lr: 1.0000e-06\n"
     ]
    }
   ],
   "source": [
    "train_losses = []\n",
    "val_losses = []\n",
    "for i in range(5):\n",
    "    print(f'{i+1}th K-fold')\n",
    "    # model = ResNet34()\n",
    "    # model = ResNet()\n",
    "    # model = Unet()\n",
    "    model = RespDNN2()\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=LR),\n",
    "        loss=keras.losses.MeanAbsoluteError(),\n",
    "        metrics=keras.metrics.MeanAbsoluteError()\n",
    "    )  \n",
    "\n",
    "    # callbacks.append(ModelCheckpoint(f'../models/230531-Resnet-L34-stmary-KF{i}', monitor='val_loss', save_best_only=True))\n",
    "    \n",
    "    history = model.fit(\n",
    "        dataset['train'][i],\n",
    "        epochs=EPOCHS,\n",
    "        callbacks=callbacks,\n",
    "        validation_data=dataset['val'][i]\n",
    "    )\n",
    "\n",
    "    train_losses.append(min(history.history['loss']))\n",
    "    val_losses.append(min(history.history['val_loss']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5802236080169678 ± 0.5789560561700089\n"
     ]
    }
   ],
   "source": [
    "train_losses = np.asarray(train_losses)\n",
    "print(f'{np.mean(train_losses)} ± {np.std(train_losses)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.536239433288574 ± 0.5087770732140575\n"
     ]
    }
   ],
   "source": [
    "val_losses = np.asarray(val_losses)\n",
    "print(f'{np.mean(val_losses)} ± {np.std(val_losses)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = preprocessing(test_patients)\n",
    "print(f'Preprocessing finished: {len(X_test)}')\n",
    "\n",
    "test_dataset = prepare_modeling(X_test, batchsize=BATCH_SIZE)\n",
    "\n",
    "for i in range(5):\n",
    "    print(f'call model {i}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
