{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-31 11:36:32.150119: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-05-31 11:36:32.196262: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-31 11:36:32.893891: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is GPU Avaliable: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "5224 1800\n",
      "(5224, 1800) (5224,)\n",
      "(5224, 1800, 1) <class 'numpy.float64'>\n",
      "(4179, 1800, 1) (4179,)\n",
      "(1045, 1800, 1) (1045,)\n"
     ]
    }
   ],
   "source": [
    "import gzip\n",
    "import pickle\n",
    "import random\n",
    "import warnings\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import os\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras.models import Model\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.layers import Conv1D, MaxPooling1D, AveragePooling1D, Dense, BatchNormalization, Activation, Add, Flatten, Dropout\n",
    "print(f'Is GPU Avaliable: {tf.config.list_physical_devices(\"GPU\")}')\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "DATA_PATH = '/root/Workspace/DataWarehouse/stMary_RRpo'\n",
    "\n",
    "with gzip.open(f'{DATA_PATH}/21_230531_resamp_sliced125_filt_stmary_train_patients.pickle.gzip', 'rb') as f:\n",
    "    dataset = pickle.load(f)\n",
    "\n",
    "print(len(dataset), len(dataset[0][0]))\n",
    "\n",
    "random.seed(42)\n",
    "random.shuffle(dataset)\n",
    "\n",
    "pleths = []\n",
    "resps = []\n",
    "for ppg, rr in dataset:\n",
    "    pleths.append(ppg.astype(np.float64))\n",
    "    resps.append(rr)\n",
    "\n",
    "pleths = np.asarray(pleths)\n",
    "resps = np.asarray(resps)\n",
    "print(pleths.shape, resps.shape)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaled_pleths = np.asarray([scaler.fit_transform(pleth.reshape(-1,1)) for pleth in pleths])\n",
    "print(scaled_pleths.shape, type(scaled_pleths[0][0][0]))\n",
    "\n",
    "ratio_tr = 0.8\n",
    "train_x, train_y = scaled_pleths[:int(len(scaled_pleths)*ratio_tr)], resps[:int(len(resps)*ratio_tr)]\n",
    "val_x, val_y = scaled_pleths[int(len(scaled_pleths)*ratio_tr):], resps[int(len(resps)*ratio_tr):]\n",
    "print(train_x.shape, train_y.shape)\n",
    "print(val_x.shape, val_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Time2Vec(keras.layers.Layer):\n",
    "    def __init__(self, output_dim=None, **kwargs):\n",
    "        super(Time2Vec, self).__init__(**kwargs)\n",
    "        self.output_dim = output_dim\n",
    "        \n",
    "        \n",
    "    def build(self, input_shape): # (sample, timestep, feature)\n",
    "        self.w = self.add_weight(name='orgW',\n",
    "                                 shape=(input_shape[1], input_shape[-1]),\n",
    "                                 initializer='uniform',\n",
    "                                 trainable=True)\n",
    "        self.p = self.add_weight(name='orgP',\n",
    "                                 shape=(input_shape[1], input_shape[-1]),\n",
    "                                 initializer='uniform',\n",
    "                                 trainable=True)\n",
    "        # (sample, timestep, output_dim)\n",
    "        self.W = self.add_weight(name='sinW',\n",
    "                                 shape=(input_shape[-1], self.output_dim-1),\n",
    "                                 initializer='uniform',\n",
    "                                 trainable=True)\n",
    "        self.P = self.add_weight(name='sinP',\n",
    "                                 shape=(input_shape[1], self.output_dim-1),\n",
    "                                 initializer='uniform',\n",
    "                                 trainable=True)\n",
    "        \n",
    "        super(Time2Vec, self).build(input_shape)\n",
    "    \n",
    "    \n",
    "    def call(self, x):\n",
    "        # 시계열 x에 지나친 변동을 주지 않고 되도록 온전하게 보존하는 linear f\n",
    "        original = self.w * x + self.p\n",
    "        sin_trans = tf.sin(tf.tensordot(x, self.W, axes=1) + self.P)\n",
    "        \n",
    "        # (sample, timestep, output_dim)\n",
    "        return tf.concat([sin_trans, original], -1) \n",
    "\n",
    "\n",
    "class RespDNN(Model):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(RespDNN, self).__init__(*args, **kwargs)\n",
    "        self.t2v1 = Time2Vec(output_dim=64)\n",
    "        self.conv1 = Conv1D(filters=64, kernel_size=3, strides=1, padding='same')\n",
    "        self.bn1 = BatchNormalization()\n",
    "\n",
    "        self.maxpool1 = MaxPooling1D(strides=2, padding='same')\n",
    "        self.subsamp1 = Conv1D(filters=64, kernel_size=2, strides=2, padding='same')\n",
    "\n",
    "        self.t2v2 = Time2Vec(output_dim=65)\n",
    "        self.conv2 = Conv1D(filters=128, kernel_size=3, strides=1, padding='same')\n",
    "        self.bn2 = BatchNormalization()\n",
    "\n",
    "        self.linear = Dense(50, activation='relu')\n",
    "        self.outputs = Dense(1)\n",
    "\n",
    "    \n",
    "    def call(self, inputs, training=None, mask=None):\n",
    "        v1 = self.t2v1(inputs)   # 주파수 정보\n",
    "        c1 = self.conv1(inputs) # 형태학적 정보\n",
    "        c1 = self.bn1(c1)\n",
    "        c1 = Activation('relu')(c1)\n",
    "        x1 = v1 + c1\n",
    "\n",
    "        x2 = self.maxpool1(x1)\n",
    "        inputs2 = self.subsamp1(inputs)\n",
    "        x2 = x2 + inputs2\n",
    "        print(x2.shape)\n",
    "\n",
    "        v2 = self.t2v2(x2)   # 주파수 정보\n",
    "        c2 = self.conv2(x2) # 형태학적 정보\n",
    "        c2 = self.bn2(c2)\n",
    "        c2 = Activation('relu')(c2)\n",
    "        x2 = v2 + c2\n",
    "        print(x2.shape)\n",
    "\n",
    "        x = self.linear(x2)\n",
    "        return self.outputs(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 100000\n",
    "BATCH_SIZE = 256\n",
    "LR = 0.001\n",
    "kf = KFold(n_splits=5)\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=15),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5),\n",
    "    # ModelCheckpoint('../models/230522-Resnet', monitor='val_loss', save_best_only=True)\n",
    "]\n",
    "\n",
    "model = RespDNN()\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=LR),\n",
    "    loss=keras.losses.MeanAbsoluteError(),\n",
    "    metrics=keras.metrics.MeanAbsoluteError()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_x, train_y)).batch(BATCH_SIZE)\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((val_x, val_y)).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100000\n",
      "21/21 [==============================] - 2s 81ms/step - loss: 4.4850 - mean_absolute_error: 4.4850 - val_loss: 4.6051 - val_mean_absolute_error: 4.6051 - lr: 1.0000e-06\n",
      "Epoch 2/100000\n",
      "21/21 [==============================] - 2s 80ms/step - loss: 4.4850 - mean_absolute_error: 4.4850 - val_loss: 4.6052 - val_mean_absolute_error: 4.6052 - lr: 1.0000e-06\n",
      "Epoch 3/100000\n",
      "21/21 [==============================] - 2s 80ms/step - loss: 4.4850 - mean_absolute_error: 4.4850 - val_loss: 4.6052 - val_mean_absolute_error: 4.6052 - lr: 1.0000e-06\n",
      "Epoch 4/100000\n",
      "21/21 [==============================] - 2s 80ms/step - loss: 4.4850 - mean_absolute_error: 4.4850 - val_loss: 4.6051 - val_mean_absolute_error: 4.6051 - lr: 1.0000e-06\n",
      "Epoch 5/100000\n",
      "21/21 [==============================] - 2s 80ms/step - loss: 4.4850 - mean_absolute_error: 4.4850 - val_loss: 4.6049 - val_mean_absolute_error: 4.6049 - lr: 1.0000e-06\n",
      "Epoch 6/100000\n",
      "21/21 [==============================] - 2s 80ms/step - loss: 4.4850 - mean_absolute_error: 4.4850 - val_loss: 4.6047 - val_mean_absolute_error: 4.6047 - lr: 1.0000e-06\n",
      "Epoch 7/100000\n",
      "21/21 [==============================] - 2s 80ms/step - loss: 4.4850 - mean_absolute_error: 4.4850 - val_loss: 4.6045 - val_mean_absolute_error: 4.6045 - lr: 1.0000e-06\n",
      "Epoch 8/100000\n",
      "21/21 [==============================] - 2s 80ms/step - loss: 4.4850 - mean_absolute_error: 4.4850 - val_loss: 4.6044 - val_mean_absolute_error: 4.6044 - lr: 1.0000e-06\n",
      "Epoch 9/100000\n",
      "21/21 [==============================] - 2s 80ms/step - loss: 4.4850 - mean_absolute_error: 4.4850 - val_loss: 4.6043 - val_mean_absolute_error: 4.6043 - lr: 1.0000e-06\n",
      "Epoch 10/100000\n",
      "21/21 [==============================] - 2s 80ms/step - loss: 4.4850 - mean_absolute_error: 4.4850 - val_loss: 4.6042 - val_mean_absolute_error: 4.6042 - lr: 1.0000e-06\n",
      "Epoch 11/100000\n",
      "21/21 [==============================] - 2s 80ms/step - loss: 4.4850 - mean_absolute_error: 4.4850 - val_loss: 4.6042 - val_mean_absolute_error: 4.6042 - lr: 1.0000e-06\n",
      "Epoch 12/100000\n",
      "21/21 [==============================] - 2s 80ms/step - loss: 4.4850 - mean_absolute_error: 4.4850 - val_loss: 4.6042 - val_mean_absolute_error: 4.6042 - lr: 1.0000e-06\n",
      "Epoch 13/100000\n",
      "21/21 [==============================] - 2s 81ms/step - loss: 4.4850 - mean_absolute_error: 4.4850 - val_loss: 4.6042 - val_mean_absolute_error: 4.6042 - lr: 1.0000e-06\n",
      "Epoch 14/100000\n",
      "21/21 [==============================] - 2s 80ms/step - loss: 4.4850 - mean_absolute_error: 4.4850 - val_loss: 4.6042 - val_mean_absolute_error: 4.6042 - lr: 1.0000e-06\n",
      "Epoch 15/100000\n",
      "21/21 [==============================] - 2s 80ms/step - loss: 4.4850 - mean_absolute_error: 4.4850 - val_loss: 4.6042 - val_mean_absolute_error: 4.6042 - lr: 1.0000e-06\n",
      "Epoch 16/100000\n",
      "21/21 [==============================] - 2s 80ms/step - loss: 4.4850 - mean_absolute_error: 4.4850 - val_loss: 4.6042 - val_mean_absolute_error: 4.6042 - lr: 1.0000e-06\n",
      "Epoch 17/100000\n",
      "21/21 [==============================] - 2s 80ms/step - loss: 4.4850 - mean_absolute_error: 4.4850 - val_loss: 4.6042 - val_mean_absolute_error: 4.6042 - lr: 1.0000e-07\n",
      "Epoch 18/100000\n",
      "21/21 [==============================] - 2s 80ms/step - loss: 4.4850 - mean_absolute_error: 4.4850 - val_loss: 4.6042 - val_mean_absolute_error: 4.6042 - lr: 1.0000e-07\n",
      "Epoch 19/100000\n",
      "21/21 [==============================] - 2s 80ms/step - loss: 4.4850 - mean_absolute_error: 4.4850 - val_loss: 4.6042 - val_mean_absolute_error: 4.6042 - lr: 1.0000e-07\n",
      "Epoch 20/100000\n",
      "21/21 [==============================] - 2s 80ms/step - loss: 4.4850 - mean_absolute_error: 4.4850 - val_loss: 4.6042 - val_mean_absolute_error: 4.6042 - lr: 1.0000e-07\n",
      "Epoch 21/100000\n",
      "21/21 [==============================] - 2s 80ms/step - loss: 4.4850 - mean_absolute_error: 4.4850 - val_loss: 4.6043 - val_mean_absolute_error: 4.6043 - lr: 1.0000e-07\n",
      "Epoch 22/100000\n",
      "21/21 [==============================] - 2s 80ms/step - loss: 4.4850 - mean_absolute_error: 4.4850 - val_loss: 4.6043 - val_mean_absolute_error: 4.6043 - lr: 1.0000e-08\n",
      "Epoch 23/100000\n",
      "21/21 [==============================] - 2s 80ms/step - loss: 4.4850 - mean_absolute_error: 4.4850 - val_loss: 4.6043 - val_mean_absolute_error: 4.6043 - lr: 1.0000e-08\n",
      "Epoch 24/100000\n",
      "21/21 [==============================] - 2s 79ms/step - loss: 4.4850 - mean_absolute_error: 4.4850 - val_loss: 4.6043 - val_mean_absolute_error: 4.6043 - lr: 1.0000e-08\n",
      "Epoch 25/100000\n",
      "21/21 [==============================] - 2s 80ms/step - loss: 4.4850 - mean_absolute_error: 4.4850 - val_loss: 4.6043 - val_mean_absolute_error: 4.6043 - lr: 1.0000e-08\n",
      "Epoch 26/100000\n",
      "21/21 [==============================] - 2s 80ms/step - loss: 4.4850 - mean_absolute_error: 4.4850 - val_loss: 4.6043 - val_mean_absolute_error: 4.6043 - lr: 1.0000e-08\n",
      "Epoch 27/100000\n",
      "21/21 [==============================] - 2s 80ms/step - loss: 4.4850 - mean_absolute_error: 4.4850 - val_loss: 4.6043 - val_mean_absolute_error: 4.6043 - lr: 1.0000e-09\n",
      "Epoch 28/100000\n",
      "21/21 [==============================] - 2s 80ms/step - loss: 4.4850 - mean_absolute_error: 4.4850 - val_loss: 4.6043 - val_mean_absolute_error: 4.6043 - lr: 1.0000e-09\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/GPU:0'):\n",
    "    history = model.fit(\n",
    "        train_dataset,\n",
    "        epochs=EPOCHS,\n",
    "        callbacks=callbacks,\n",
    "        validation_data=val_dataset\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
